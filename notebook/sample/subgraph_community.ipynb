{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0c6433",
   "metadata": {},
   "source": [
    "# Community Subgraph Density Analysis\n",
    "\n",
    "This notebook analyzes community detection results from run 142 by:\n",
    "1. Loading the full graph from CSV\n",
    "2. Loading community assignments from JSON\n",
    "3. Creating subgraphs for each community\n",
    "4. Computing density metrics\n",
    "5. Ranking communities by density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3294966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9840fa6",
   "metadata": {},
   "source": [
    "## 1. Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37c7424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph data with 108071 nodes\n",
      "Columns: ['id', 'd_properties_document_title', 'd_properties_title_encode', 'cites_ids']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_properties_document_title</th>\n",
       "      <th>d_properties_title_encode</th>\n",
       "      <th>cites_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Therefore sign</td>\n",
       "      <td>Therefore_sign</td>\n",
       "      <td>[6352, 2622, 5393, 3079, 15650, 33906, 13375, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Watchman (law enforcement)</td>\n",
       "      <td>Watchman_(law_enforcement)</td>\n",
       "      <td>[4286, 4215, 2819, 864, 5115, 3220, 21000, 156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Super Bowl 50 halftime show</td>\n",
       "      <td>Super_Bowl_50_halftime_show</td>\n",
       "      <td>[6341, 1832, 360, 1739, 4108, 138, 73, 1941, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>A Whiter Shade of Pale</td>\n",
       "      <td>A_Whiter_Shade_of_Pale</td>\n",
       "      <td>[547, 1646, 3958, 423, 9518, 8998, 9020, 8938,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Globe</td>\n",
       "      <td>Globe</td>\n",
       "      <td>[258, 2819, 600, 1188, 1564, 15616, 21607, 123...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  d_properties_document_title    d_properties_title_encode  \\\n",
       "0   0               Therefore sign               Therefore_sign   \n",
       "1   1   Watchman (law enforcement)   Watchman_(law_enforcement)   \n",
       "2   3  Super Bowl 50 halftime show  Super_Bowl_50_halftime_show   \n",
       "3   5       A Whiter Shade of Pale       A_Whiter_Shade_of_Pale   \n",
       "4   6                        Globe                        Globe   \n",
       "\n",
       "                                           cites_ids  \n",
       "0  [6352, 2622, 5393, 3079, 15650, 33906, 13375, ...  \n",
       "1  [4286, 4215, 2819, 864, 5115, 3220, 21000, 156...  \n",
       "2  [6341, 1832, 360, 1739, 4108, 138, 73, 1941, 1...  \n",
       "3  [547, 1646, 3958, 423, 9518, 8998, 9020, 8938,...  \n",
       "4  [258, 2819, 600, 1188, 1564, 15616, 21607, 123...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file containing the full graph\n",
    "csv_path = \"/home/zeneto/projects/kg4ai-community_detection/data/v0.0/df_nq_version0.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Loaded graph data with {len(df)} nodes\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ff86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available algorithms: ['infomap', 'louvain', 'leiden', 'k-means']\n",
      "infomap: 1249 communities\n",
      "louvain: 24 communities\n",
      "leiden: 19 communities\n",
      "k-means: 40 communities\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file containing community assignments\n",
    "json_path = \"/home/zeneto/projects/kg4ai-community_detection/community_detection/output/run142-NQv0-best_run/run142_raw_communities.json\"\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    communities_data = json.load(f)\n",
    "\n",
    "print(\"Available algorithms:\", list(communities_data.keys()))\n",
    "for algo, communities in communities_data.items():\n",
    "    print(f\"{algo}: {len(communities)} communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92026c",
   "metadata": {},
   "source": [
    "## 2. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98246e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique nodes in the graph: 108071\n",
      "Nodes with citation data: 108071\n"
     ]
    }
   ],
   "source": [
    "# Parse the cites_ids column (convert string representation of list to actual list)\n",
    "df['cites_ids_parsed'] = df['cites_ids'].apply(literal_eval)\n",
    "\n",
    "# Create a mapping from node ID to all its cited nodes\n",
    "node_citations = {}\n",
    "all_nodes = set(df['id'].tolist())\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    node_id = row['id']\n",
    "    cited_nodes = row['cites_ids_parsed']\n",
    "    node_title = row['d_properties_document_title']\n",
    "    node_citations[node_id] = cited_nodes\n",
    "    # Add cited nodes to our set of all nodes\n",
    "    all_nodes.update(cited_nodes)\n",
    "\n",
    "print(f\"Total unique nodes in the graph: {len(all_nodes)}\")\n",
    "print(f\"Nodes with citation data: {len(node_citations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ce130",
   "metadata": {},
   "source": [
    "## 3. Build the Full Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733de5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full graph created:\n",
      "  Nodes: 108071\n",
      "  Edges: 5122983\n",
      "  Graph density: 0.000439\n"
     ]
    }
   ],
   "source": [
    "# Create the full graph using NetworkX\n",
    "G = nx.DiGraph()  # Using directed graph since we have citation relationships\n",
    "\n",
    "# Add all nodes\n",
    "G.add_nodes_from(all_nodes)\n",
    "\n",
    "# Add node attributes (titles)\n",
    "for node_id, node_title in zip(df['id'], df['d_properties_document_title']):\n",
    "    G.nodes[node_id]['title'] = node_title  \n",
    "\n",
    "# Add edges (citations)\n",
    "edges = []\n",
    "for node_id, cited_nodes in node_citations.items():\n",
    "    for cited_node in cited_nodes:\n",
    "        edges.append((node_id, cited_node))\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "print(f\"Full graph created:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Graph density: {nx.density(G):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b52751",
   "metadata": {},
   "source": [
    "## 4. Analyze Communities by Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77772de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing infomap with 1249 communities...\n",
      "  Processed 50/1249 communities\n",
      "  Processed 100/1249 communities\n",
      "  Processed 150/1249 communities\n",
      "  Processed 200/1249 communities\n",
      "  Processed 250/1249 communities\n",
      "  Processed 300/1249 communities\n",
      "  Processed 400/1249 communities\n",
      "\n",
      "Analyzing louvain with 24 communities...\n",
      "\n",
      "Analyzing leiden with 19 communities...\n",
      "\n",
      "Analyzing k-means with 40 communities...\n",
      "\n",
      "Analysis complete. Total communities analyzed: 460\n"
     ]
    }
   ],
   "source": [
    "def analyze_community_subgraphs(graph, communities_dict):\n",
    "    \"\"\"\n",
    "    Analyze subgraphs for each community and compute density metrics.\n",
    "    \n",
    "    Args:\n",
    "        graph: NetworkX graph object\n",
    "        communities_dict: Dictionary with algorithm names as keys and community lists as values\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with analysis results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for algorithm, communities in communities_dict.items():\n",
    "        if len(communities) == 0:\n",
    "            print(f\"Skipping {algorithm} - no communities found\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nAnalyzing {algorithm} with {len(communities)} communities...\")\n",
    "        \n",
    "        for comm_id, community_nodes in enumerate(communities):\n",
    "            if len(community_nodes) < 20:\n",
    "                # Skip communities with fewer than 2 nodes (can't compute density)\n",
    "                continue\n",
    "                \n",
    "            # Create subgraph for this community\n",
    "            subgraph = graph.subgraph(community_nodes)\n",
    "            \n",
    "            # Compute metrics\n",
    "            num_nodes = subgraph.number_of_nodes()\n",
    "            num_edges = subgraph.number_of_edges()\n",
    "            \n",
    "            # NetworkX density calculation\n",
    "            if num_nodes > 1:\n",
    "                density = nx.density(subgraph)\n",
    "            else:\n",
    "                density = 0.0\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Algorithm': algorithm,\n",
    "                'Community_ID': comm_id,\n",
    "                'Num_Nodes': num_nodes,\n",
    "                'Num_Edges': num_edges,\n",
    "                'Density': density\n",
    "            })\n",
    "            \n",
    "            # Progress indicator for large community sets\n",
    "            if (comm_id + 1) % 50 == 0:\n",
    "                print(f\"  Processed {comm_id + 1}/{len(communities)} communities\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the analysis\n",
    "results_df = analyze_community_subgraphs(G, communities_data)\n",
    "print(f\"\\nAnalysis complete. Total communities analyzed: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d296f",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics by Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcd31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics by Algorithm:\n",
      "==================================================\n",
      "\n",
      "INFOMAP:\n",
      "  Total communities: 377\n",
      "  Average density: 0.199457\n",
      "  Median density: 0.140336\n",
      "  Max density: 0.782656\n",
      "  Min density: 0.002168\n",
      "  Average community size: 277.44 nodes\n",
      "  Average edges per community: 7273.71\n",
      "\n",
      "LOUVAIN:\n",
      "  Total communities: 24\n",
      "  Average density: 0.170148\n",
      "  Median density: 0.026509\n",
      "  Max density: 0.878546\n",
      "  Min density: 0.001449\n",
      "  Average community size: 4480.58 nodes\n",
      "  Average edges per community: 150726.08\n",
      "\n",
      "LEIDEN:\n",
      "  Total communities: 19\n",
      "  Average density: 0.188669\n",
      "  Median density: 0.005739\n",
      "  Max density: 0.836327\n",
      "  Min density: 0.001390\n",
      "  Average community size: 5659.68 nodes\n",
      "  Average edges per community: 190744.58\n",
      "\n",
      "K-MEANS:\n",
      "  Total communities: 40\n",
      "  Average density: 0.005001\n",
      "  Median density: 0.004184\n",
      "  Max density: 0.016522\n",
      "  Min density: 0.000600\n",
      "  Average community size: 2688.35 nodes\n",
      "  Average edges per community: 34547.38\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics by algorithm\n",
    "if len(results_df) > 0:\n",
    "    print(\"Summary Statistics by Algorithm:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for algorithm in results_df['Algorithm'].unique():\n",
    "        algo_data = results_df[results_df['Algorithm'] == algorithm]\n",
    "        \n",
    "        print(f\"\\n{algorithm.upper()}:\")\n",
    "        print(f\"  Total communities: {len(algo_data)}\")\n",
    "        print(f\"  Average density: {algo_data['Density'].mean():.6f}\")\n",
    "        print(f\"  Median density: {algo_data['Density'].median():.6f}\")\n",
    "        print(f\"  Max density: {algo_data['Density'].max():.6f}\")\n",
    "        print(f\"  Min density: {algo_data['Density'].min():.6f}\")\n",
    "        print(f\"  Average community size: {algo_data['Num_Nodes'].mean():.2f} nodes\")\n",
    "        print(f\"  Average edges per community: {algo_data['Num_Edges'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"No valid communities found for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7cee2",
   "metadata": {},
   "source": [
    "## 6. Ranked Communities by Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb104c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Communities by Density:\n",
      "======================================================================\n",
      "Algorithm  Community_ID  Num_Nodes  Num_Edges  Density\n",
      "  louvain            13         48       1982 0.878546\n",
      "   leiden            17         50       2049 0.836327\n",
      "  infomap           177         53       2157 0.782656\n",
      "  infomap           364         21        325 0.773810\n",
      "  infomap           114        158      19148 0.771910\n",
      "  infomap           244         46       1418 0.685024\n",
      "  infomap           333         27        473 0.673789\n",
      "  infomap           339         27        450 0.641026\n",
      "  infomap           253         32        633 0.638105\n",
      "  infomap           326         26        413 0.635385\n",
      "  infomap           372         22        290 0.627706\n",
      "  infomap           225         37        836 0.627628\n",
      "  infomap           358         25        373 0.621667\n",
      "  infomap           354         22        287 0.621212\n",
      "  infomap           323         23        314 0.620553\n",
      "  infomap           147         66       2613 0.609091\n",
      "  infomap           293         39        893 0.602564\n",
      "  infomap           357         25        361 0.601667\n",
      "  infomap           238         39        886 0.597841\n",
      "   leiden            13        113       7527 0.594738\n",
      "\n",
      "\n",
      "Bottom 10 Communities by Density:\n",
      "======================================================================\n",
      "Algorithm  Community_ID  Num_Nodes  Num_Edges  Density\n",
      "  k-means            33       1925       6619 0.001787\n",
      "  k-means            13       3136      16733 0.001702\n",
      "  k-means            27       1672       4404 0.001576\n",
      "  k-means             4       1051       1698 0.001539\n",
      "  louvain            10      19772     566373 0.001449\n",
      "  k-means            32       3658      19046 0.001424\n",
      "   leiden             0      20754     598685 0.001390\n",
      "  k-means             2       8006      64758 0.001010\n",
      "  k-means            23       3976      12401 0.000785\n",
      "  k-means            28       3145       5931 0.000600\n"
     ]
    }
   ],
   "source": [
    "# Rank all communities by density (highest to lowest)\n",
    "if len(results_df) > 0:\n",
    "    ranked_communities = results_df.sort_values('Density', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"Top 20 Communities by Density:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    top_20 = ranked_communities.head(20)\n",
    "    \n",
    "    # Format the display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    print(top_20.to_string(index=False, float_format='%.6f'))\n",
    "    \n",
    "    print(f\"\\n\\nBottom 10 Communities by Density:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    bottom_10 = ranked_communities.tail(10)\n",
    "    print(bottom_10.to_string(index=False, float_format='%.6f'))\n",
    "else:\n",
    "    print(\"No communities to rank.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac508034",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce76930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /home/zeneto/projects/kg4ai-community_detection/notebook/sample/community_density_analysis.csv\n",
      "Summary statistics saved to: /home/zeneto/projects/kg4ai-community_detection/notebook/sample/algorithm_summary_stats.csv\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Save the complete ranked results to CSV\n",
    "if len(results_df) > 0:\n",
    "    output_path = \"/home/zeneto/projects/kg4ai-community_detection/notebook/sample/community_density_analysis.csv\"\n",
    "    ranked_communities.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "    \n",
    "    # Also save summary statistics\n",
    "    summary_stats = []\n",
    "    for algorithm in results_df['Algorithm'].unique():\n",
    "        algo_data = results_df[results_df['Algorithm'] == algorithm]\n",
    "        summary_stats.append({\n",
    "            'Algorithm': algorithm,\n",
    "            'Total_Communities': len(algo_data),\n",
    "            'Avg_Density': algo_data['Density'].mean(),\n",
    "            'Median_Density': algo_data['Density'].median(),\n",
    "            'Max_Density': algo_data['Density'].max(),\n",
    "            'Min_Density': algo_data['Density'].min(),\n",
    "            'Avg_Community_Size': algo_data['Num_Nodes'].mean(),\n",
    "            'Avg_Edges_Per_Community': algo_data['Num_Edges'].mean()\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_path = \"/home/zeneto/projects/kg4ai-community_detection/notebook/sample/algorithm_summary_stats.csv\"\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Summary statistics saved to: {summary_path}\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "else:\n",
    "    print(\"No results to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b3412",
   "metadata": {},
   "source": [
    "## 8. Additional Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f81762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Community_ID</th>\n",
       "      <th>Num_Nodes</th>\n",
       "      <th>Num_Edges</th>\n",
       "      <th>Density</th>\n",
       "      <th>Node_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>louvain</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>1982</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infomap</td>\n",
       "      <td>114</td>\n",
       "      <td>158</td>\n",
       "      <td>19148</td>\n",
       "      <td>0.771910</td>\n",
       "      <td>100-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>infomap</td>\n",
       "      <td>73</td>\n",
       "      <td>297</td>\n",
       "      <td>16795</td>\n",
       "      <td>0.191043</td>\n",
       "      <td>200-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>infomap</td>\n",
       "      <td>40</td>\n",
       "      <td>320</td>\n",
       "      <td>19325</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>300-400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>infomap</td>\n",
       "      <td>84</td>\n",
       "      <td>421</td>\n",
       "      <td>10283</td>\n",
       "      <td>0.058155</td>\n",
       "      <td>400-500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm  Community_ID  Num_Nodes  Num_Edges   Density Node_Range\n",
       "0     louvain            13         48       1982  0.878546      0-100\n",
       "4     infomap           114        158      19148  0.771910    100-200\n",
       "154   infomap            73        297      16795  0.191043    200-300\n",
       "155   infomap            40        320      19325  0.189312    300-400\n",
       "315   infomap            84        421      10283  0.058155    400-500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define node bins\n",
    "bins = [0, 100, 200, 300, 400, 500]\n",
    "labels = [\"0-100\", \"100-200\", \"200-300\", \"300-400\", \"400-500\"]\n",
    "\n",
    "# Add a column indicating which bin each community belongs to\n",
    "ranked_communities[\"Node_Range\"] = pd.cut(ranked_communities[\"Num_Nodes\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# remove communities that do not fall into any bin (e.g., >500 nodes)\n",
    "ranked_communities = ranked_communities.dropna(subset=[\"Node_Range\"])\n",
    "\n",
    "# Get the most dense community in each bin\n",
    "most_dense_per_bin = ranked_communities.loc[ranked_communities.groupby(\"Node_Range\")[\"Density\"].idxmax()]\n",
    "most_dense_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318103ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph 0 saved to /home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_0.graphml\n",
      "Subgraph 1 saved to /home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_1.graphml\n",
      "Subgraph 2 saved to /home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_2.graphml\n",
      "Subgraph 3 saved to /home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_3.graphml\n",
      "Subgraph 4 saved to /home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_4.graphml\n",
      "Subgraph 0: Nodes=48, Edges=1982, Density=0.878546\n",
      "  Top keywords: {'gun': 45, 'laws': 45, 'new': 4, 'carry': 2, 'california': 2, 'states': 2, 'united': 2, 'virginia': 2, 'carolina': 2, 'campus': 1}\n",
      "Subgraph 1: Nodes=158, Edges=19148, Density=0.771910\n",
      "  Top keywords: {'visa': 152, 'citizens': 86, 'requirements': 85, 'policy': 66, 'south': 4, 'united': 4, 'republic': 3, 'korea': 3, 'north': 3, 'saint': 3}\n",
      "Subgraph 2: Nodes=297, Edges=16795, Density=0.191043\n",
      "  Top keywords: {'series': 61, 'film': 20, 'parks': 14, 'recreation': 14, 'season': 13, 'episodes': 12, 'house': 6, 'killing': 6, 'characters': 5, 'arrested': 4}\n",
      "Subgraph 3: Nodes=320, Edges=19325, Density=0.189312\n",
      "  Top keywords: {'war': 60, 'american': 60, 'civil': 58, 'battle': 57, 'states': 25, 'united': 17, 'slavery': 16, 'confederate': 13, 'act': 8, 'fort': 8}\n",
      "Subgraph 4: Nodes=421, Edges=10283, Density=0.058155\n",
      "  Top keywords: {'cricket': 206, 'world': 63, 'cup': 60, 'team': 55, 'international': 34, 'indian': 33, 'national': 29, 'india': 29, 'records': 26, 'league': 26}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_community_subgraph(graph, communities_data, algorithm, community_id):\n",
    "    \"\"\"\n",
    "    Returns the subgraph for a given algorithm and community ID.\n",
    "\n",
    "    Args:\n",
    "        graph: NetworkX graph object (full graph)\n",
    "        communities_data: dict of {algorithm: list of communities}\n",
    "        algorithm: str, algorithm name\n",
    "        community_id: int, index of the community in communities_data[algorithm]\n",
    "\n",
    "    Returns:\n",
    "        NetworkX subgraph object\n",
    "    \"\"\"\n",
    "    nodes = communities_data[algorithm][community_id]\n",
    "    return graph.subgraph(nodes).copy()\n",
    "\n",
    "# Example usage for most_dense_per_bin:\n",
    "subgraphs = []\n",
    "for _, row in most_dense_per_bin.iterrows():\n",
    "    subgraph = get_community_subgraph(G, communities_data, row['Algorithm'], row['Community_ID'])\n",
    "    subgraphs.append(subgraph)\n",
    "\n",
    "# Save the subgraphs to GraphML files\n",
    "for i, sg in enumerate(subgraphs):\n",
    "    output_file = f\"/home/zeneto/projects/kg4ai-community_detection/notebook/sample/subgraph_{i}.graphml\"\n",
    "    nx.write_graphml(sg, output_file)\n",
    "    print(f\"Subgraph {i} saved to {output_file}\")\n",
    "\n",
    "stop_words = {\n",
    "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to',\n",
    "    'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be',\n",
    "    'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'list'\n",
    "}\n",
    "\n",
    "for i, sg in enumerate(subgraphs):\n",
    "    print(f\"Subgraph {i}: Nodes={sg.number_of_nodes()}, Edges={sg.number_of_edges()}, Density={nx.density(sg):.6f}\")\n",
    "\n",
    "    # Print statistics of the first subgraph\n",
    "    subgraphs[1].number_of_nodes(), subgraphs[1].number_of_edges(), nx.density(subgraphs[1])\n",
    "\n",
    "    # Find keywords in the titles of the nodes in the subgraph\n",
    "    titles = [data['title'] for node, data in sg.nodes(data=True) if 'title' in data]\n",
    "    text = ' '.join(titles).lower()\n",
    "    # Use regex to extract only ASCII words with 3+ letters\n",
    "    all_words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text)\n",
    "    word_freq = pd.Series(all_words).value_counts()\n",
    "    word_freq = word_freq[~word_freq.index.isin(stop_words)]\n",
    "    \n",
    "    print(f\"  Top keywords: {word_freq.head(10).to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg4ai-community-detection-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
