{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b875d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score, rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a3356",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8421736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example category: 2017 American television seasons\n",
      "Articles: ['The_Walking_Dead_(season_8)', 'Grey%27s_Anatomy_(season_14)', 'The_Walking_Dead_(season_7)', 'America%27s_Got_Talent_(season_12)', 'Grey%27s_Anatomy_(season_14)']\n"
     ]
    }
   ],
   "source": [
    "# Path to your file\n",
    "file_path = \"/home/zeneto/projects/kg4ai-community_detection/data/wiki_categories/nq-train-all.jsonl\"\n",
    "\n",
    "# Dictionary to store categories → list of titles\n",
    "category_dict = defaultdict(list)\n",
    "\n",
    "# Read line by line\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Skip empty lines\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Parse JSON line\n",
    "        data = json.loads(line)\n",
    "\n",
    "        # Extract title and categorias\n",
    "        title = data.get(\"title\")\n",
    "        categorias = data.get(\"categorias\", [])\n",
    "\n",
    "        # Add title under each category\n",
    "        for cat in categorias:\n",
    "            category_dict[cat].append(title)\n",
    "\n",
    "# Optionally convert defaultdict to normal dict\n",
    "category_dict = dict(category_dict)\n",
    "\n",
    "# Example: print one category\n",
    "print(\"Example category:\", next(iter(category_dict.keys())))\n",
    "print(\"Articles:\", category_dict[next(iter(category_dict.keys()))][:5])  # show first 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5cf4bd",
   "metadata": {},
   "source": [
    "## 2. Basic info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3857c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique categories: 217562\n",
      "Category with the most titles: English-language films (17020 articles)\n",
      "Category with the fewest titles: Computer-assisted surgery (1 articles)\n",
      "\n",
      "Average titles per category: 11.81\n",
      "Median titles per category: 3.0\n",
      "Standard deviation (titles per category): 78.00\n",
      "\n",
      "Top 10 categories by number of articles:\n",
      "1. English-language films: 17020\n",
      "2. American films: 15164\n",
      "3. Living people: 12082\n",
      "4. English-language television programs: 10296\n",
      "5. Billboard Hot 100 number-one singles: 3956\n",
      "6. UK Singles Chart number-one singles: 3533\n",
      "7. IMAX films: 3147\n",
      "8. American male film actors: 3104\n",
      "9. American male television actors: 2958\n",
      "10. American television actresses: 2724\n"
     ]
    }
   ],
   "source": [
    "# --- Basic info ---\n",
    "total_categories = len(category_dict)\n",
    "print(f\"Total number of unique categories: {total_categories}\")\n",
    "\n",
    "# --- Count how many titles per category ---\n",
    "category_counts = {cat: len(titles) for cat, titles in category_dict.items()}\n",
    "\n",
    "# --- Find category extremes ---\n",
    "most_common_cat = max(category_counts, key=category_counts.get)\n",
    "least_common_cat = min(category_counts, key=category_counts.get)\n",
    "print(f\"Category with the most titles: {most_common_cat} ({category_counts[most_common_cat]} articles)\")\n",
    "print(f\"Category with the fewest titles: {least_common_cat} ({category_counts[least_common_cat]} articles)\")\n",
    "\n",
    "# --- Calculate averages and dispersion for category_counts ---\n",
    "avg_titles_per_category = statistics.mean(category_counts.values())\n",
    "median_titles_per_category = statistics.median(category_counts.values())\n",
    "stdev_titles_per_category = statistics.pstdev(category_counts.values())\n",
    "\n",
    "print(f\"\\nAverage titles per category: {avg_titles_per_category:.2f}\")\n",
    "print(f\"Median titles per category: {median_titles_per_category}\")\n",
    "print(f\"Standard deviation (titles per category): {stdev_titles_per_category:.2f}\")\n",
    "\n",
    "# --- Sort categories by article count ---\n",
    "sorted_cats = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 10 categories by number of articles:\")\n",
    "for i, (cat, count) in enumerate(sorted_cats[:10]):\n",
    "    print(f\"{i + 1}. {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e06d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles under 'Greek goddesses':\n",
      "- Persephone\n",
      "- Theia\n",
      "- Rhea_(mythology)\n",
      "- List_of_Greek_mythological_figures\n",
      "- Persephone\n",
      "- List_of_Greek_mythological_figures\n",
      "- Hera\n",
      "- Hera\n",
      "- List_of_Greek_mythological_figures\n",
      "- List_of_Greek_mythological_figures\n",
      "- Aphrodite\n",
      "- Gaia\n",
      "- Selene\n",
      "- Aphrodite\n",
      "- List_of_Greek_mythological_figures\n",
      "- List_of_Greek_mythological_figures\n",
      "- List_of_Greek_mythological_figures\n",
      "- Aphrodite\n",
      "- Hera\n",
      "- Persephone\n",
      "- List_of_Greek_mythological_figures\n",
      "- Gaia_(mythology)\n",
      "- Moirai\n",
      "- Circe\n",
      "- Hecate\n",
      "- Charites\n",
      "- Eileithyia\n",
      "- Circe\n",
      "- Nike_(mythology)\n",
      "- List_of_Greek_mythological_figures\n",
      "- Charites\n",
      "- List_of_Greek_mythological_figures\n",
      "- List_of_Greek_mythological_figures\n",
      "- Hera\n"
     ]
    }
   ],
   "source": [
    "# --- Example: Get all titles from a specific category ---\n",
    "query = \"Greek goddesses\"  # change this to any category you want\n",
    "if query in category_dict:\n",
    "    print(f\"Articles under '{query}':\")\n",
    "    for title in category_dict[query]:  # show first 10 titles\n",
    "        print(\"-\", title)\n",
    "else:\n",
    "    print(f\"\\nCategory '{query}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06439a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title(s) with the most categories (244):\n",
      "- Fourth_Geneva_Convention\n",
      "\n",
      "Title(s) with the fewest categories (1):\n",
      "- Sleepy_Hollow_(season_4)\n",
      "- The_Night_Shift_(season_4)\n",
      "- Suits_(season_7)\n",
      "- Switched_at_Birth_(season_5)\n",
      "- Sense8_(season_2)\n",
      "- Reign_(season_4)\n",
      "- MasterChef_Junior_(U.S._season_5)\n",
      "- Xerosere\n",
      "- Environmental_data\n",
      "- List_of_members_of_the_House_of_Representatives_of_Nigeria,_2015%E2%80%93present\n",
      "\n",
      "Average categories per title: 7.33\n",
      "Median categories per title: 5\n",
      "Standard deviation (categories per title): 8.42\n",
      "\n",
      "Top 10 titles by number of categories:\n",
      "1. Fourth_Geneva_Convention: 244\n",
      "2. First_Geneva_Convention: 242\n",
      "3. Third_Geneva_Convention: 242\n",
      "4. Montreal_Protocol: 232\n",
      "5. Vienna_Convention_for_the_Protection_of_the_Ozone_Layer: 232\n",
      "6. Convention_on_Biological_Diversity: 230\n",
      "7. Convention_on_the_Rights_of_the_Child: 225\n",
      "8. International_Convention_on_the_Elimination_of_All_Forms_of_Racial_Discrimination: 223\n",
      "9. Chemical_Weapons_Convention: 221\n",
      "10. Convention_on_the_Elimination_of_All_Forms_of_Discrimination_Against_Women: 218\n"
     ]
    }
   ],
   "source": [
    "# --- Reverse mapping: count how many categories each title belongs to ---\n",
    "title_to_categories = defaultdict(set)\n",
    "for cat, titles in category_dict.items():\n",
    "    for title in titles:\n",
    "        title_to_categories[title].add(cat)\n",
    "\n",
    "title_category_counts = {title: len(cats) for title, cats in title_to_categories.items()}\n",
    "\n",
    "# --- Find title extremes ---\n",
    "max_cats = max(title_category_counts.values())\n",
    "min_cats = min(title_category_counts.values())\n",
    "most_categorized_titles = [t for t, c in title_category_counts.items() if c == max_cats]\n",
    "least_categorized_titles = [t for t, c in title_category_counts.items() if c == min_cats]\n",
    "\n",
    "print(f\"Title(s) with the most categories ({max_cats}):\")\n",
    "for t in most_categorized_titles:\n",
    "    print(\"-\", t)\n",
    "\n",
    "print(f\"\\nTitle(s) with the fewest categories ({min_cats}):\")\n",
    "for t in least_categorized_titles[:10]:  # limit output\n",
    "    print(\"-\", t)\n",
    "\n",
    "# --- Calculate averages and dispersion for title_category_counts ---\n",
    "avg_categories_per_title = statistics.mean(title_category_counts.values())\n",
    "median_categories_per_title = statistics.median(title_category_counts.values())\n",
    "stdev_categories_per_title = statistics.pstdev(title_category_counts.values())\n",
    "\n",
    "print(f\"\\nAverage categories per title: {avg_categories_per_title:.2f}\")\n",
    "print(f\"Median categories per title: {median_categories_per_title}\")\n",
    "print(f\"Standard deviation (categories per title): {stdev_categories_per_title:.2f}\")\n",
    "\n",
    "# --- Optional: show top 10 titles by number of categories ---\n",
    "sorted_titles = sorted(title_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 10 titles by number of categories:\")\n",
    "for i, (title, count) in enumerate(sorted_titles[:10]):\n",
    "    print(f\"{i + 1}. {title}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8667e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique article titles: 108013\n",
      "Example titles: ['Cash_Explosion', 'May_3', 'Scanf_format_string', 'Trelawny_Parish', 'Marcus_Chong', 'Street_Fighter:_The_Legend_of_Chun-Li', 'Income_inequality_in_India', 'My_Two_Dads', 'Petroleum', 'Airfoil']\n"
     ]
    }
   ],
   "source": [
    "# Get all titles from all categories\n",
    "all_titles = []\n",
    "\n",
    "for titles in category_dict.values():\n",
    "    all_titles.extend(titles)\n",
    "\n",
    "# Convert to a set to get only unique ones\n",
    "unique_titles = set(all_titles)\n",
    "\n",
    "# Count them\n",
    "print(f\"Total number of unique article titles: {len(unique_titles)}\")\n",
    "\n",
    "# Optionally, see a few examples\n",
    "print(\"Example titles:\", list(unique_titles)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac06b2e",
   "metadata": {},
   "source": [
    "## 3. Match Category and Articles' ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02d6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully matched: 2569240/2569242 titles (100.00%)\n",
      "❌ Missing titles: 1\n",
      "Total categories with assigned IDs: 217562\n",
      "\n",
      "Examples of missing titles:\n",
      "- NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Ler o CSV\n",
    "df = pd.read_csv(\"/home/zeneto/projects/kg4ai-community_detection/data/v0.0/df_nq_version0.csv\")\n",
    "\n",
    "# 2. Create mapping {encoded_title → id}\n",
    "title_to_id = dict(zip(df[\"d_properties_title_encode\"], df[\"id\"]))\n",
    "\n",
    "# Detect duplicates in CSV\n",
    "if df[\"d_properties_title_encode\"].duplicated().any():\n",
    "    print(\"⚠️ Warning: There are duplicate encoded titles in your CSV!\")\n",
    "    duplicates = df[df[\"d_properties_title_encode\"].duplicated(keep=False)]\n",
    "    print(duplicates)\n",
    "\n",
    "# 3. Build the new dictionary + track missing\n",
    "category_dict_id = {}\n",
    "missing_titles = set()\n",
    "matched_count = 0\n",
    "total_titles = 0\n",
    "category_id_counter = 0  # Initialize the counter for category IDs\n",
    "\n",
    "for category, titles in category_dict.items():\n",
    "    ids = []\n",
    "    for title in titles:\n",
    "        total_titles += 1\n",
    "        if title in title_to_id:\n",
    "            ids.append(title_to_id[title])\n",
    "            matched_count += 1\n",
    "        else:\n",
    "            missing_titles.add(title)\n",
    "    # 4. Assign Category ID\n",
    "    if ids:\n",
    "        # Create the category ID (e.g., 'cat_0', 'cat_1', ...)\n",
    "        category_id = f\"cat_{category_id_counter}\"\n",
    "        category_dict_id[category_id] = ids\n",
    "        category_id_counter += 1\n",
    "\n",
    "# --- Summary Report ---\n",
    "print(f\"✅ Successfully matched: {matched_count}/{total_titles} titles ({matched_count/total_titles:.2%})\")\n",
    "print(f\"❌ Missing titles: {len(missing_titles)}\")\n",
    "print(f\"Total categories with assigned IDs: {category_id_counter}\")\n",
    "\n",
    "# --- Optionally show some missing examples ---\n",
    "if missing_titles:\n",
    "    print(\"\\nExamples of missing titles:\")\n",
    "    for t in list(missing_titles)[:10]:\n",
    "        print(\"-\", t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b5bd9",
   "metadata": {},
   "source": [
    "## 4. Load Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046f2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available algorithms: ['infomap', 'louvain', 'leiden', 'k-means']\n",
      "infomap: 1249 communities\n",
      "louvain: 24 communities\n",
      "leiden: 19 communities\n",
      "k-means: 40 communities\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file containing community assignments\n",
    "json_path = \"/home/zeneto/projects/kg4ai-community_detection/community_detection/output/run142-NQv0-best_run/run142_raw_communities.json\"\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    communities_data = json.load(f)\n",
    "\n",
    "print(\"Available algorithms:\", list(communities_data.keys()))\n",
    "for algo, communities in communities_data.items():\n",
    "    print(f\"{algo}: {len(communities)} communities\")\n",
    "\n",
    "# Select the algorithm with the best Modularity\n",
    "selected_algorithm = \"leiden\"\n",
    "communities = communities_data.get(selected_algorithm, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf741de",
   "metadata": {},
   "source": [
    "### Check IDs intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0255a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique IDs in category_dict_id: 108,012\n",
      "Total unique IDs in communities: 107,534\n",
      "\n",
      "✅ IDs in both: 107,481\n",
      "⚠️ IDs only in category_dict_id: 531\n",
      "⚠️ IDs only in communities: 53\n",
      "\n",
      "Examples of IDs only in category_dict_id:\n",
      "[40963, 26628, 53260, 67604, 38936, 92184, 10267, 14367, 63520, 86048]\n",
      "\n",
      "Examples of IDs only in communities:\n",
      "[100867, 68487, 41096, 87816, 98699, 89234, 92052, 99860, 34710, 36503]\n"
     ]
    }
   ],
   "source": [
    "# --- Extract unique IDs from category_dict_id ---\n",
    "category_ids = set()\n",
    "for ids in category_dict_id.values():\n",
    "    category_ids.update(ids)\n",
    "\n",
    "print(f\"Total unique IDs in category_dict_id: {len(category_ids):,}\")\n",
    "\n",
    "# --- Extract unique IDs from communities ---\n",
    "community_ids = set()\n",
    "for community in communities:\n",
    "    community_ids.update(community)\n",
    "\n",
    "print(f\"Total unique IDs in communities: {len(community_ids):,}\")\n",
    "\n",
    "# --- Compare ---\n",
    "in_both = category_ids & community_ids\n",
    "only_in_category = category_ids - community_ids\n",
    "only_in_communities = community_ids - category_ids\n",
    "\n",
    "print(f\"\\n✅ IDs in both: {len(in_both):,}\")\n",
    "print(f\"⚠️ IDs only in category_dict_id: {len(only_in_category):,}\")\n",
    "print(f\"⚠️ IDs only in communities: {len(only_in_communities):,}\")\n",
    "\n",
    "# --- Show some examples if mismatches exist ---\n",
    "if only_in_category:\n",
    "    print(\"\\nExamples of IDs only in category_dict_id:\")\n",
    "    print(list(only_in_category)[:10])\n",
    "\n",
    "if only_in_communities:\n",
    "    print(\"\\nExamples of IDs only in communities:\")\n",
    "    print(list(only_in_communities)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b044d51",
   "metadata": {},
   "source": [
    "### Check Categories from Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ac43ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_properties_document_title</th>\n",
       "      <th>d_properties_title_encode</th>\n",
       "      <th>cites_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70509</th>\n",
       "      <td>72150</td>\n",
       "      <td>Fourth Geneva Convention</td>\n",
       "      <td>Fourth_Geneva_Convention</td>\n",
       "      <td>[14089, 25290, 36231, 38878, 13135, 5924, 6530...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id d_properties_document_title d_properties_title_encode  \\\n",
       "70509  72150    Fourth Geneva Convention  Fourth_Geneva_Convention   \n",
       "\n",
       "                                               cites_ids  \n",
       "70509  [14089, 25290, 36231, 38878, 13135, 5924, 6530...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find title on df\n",
    "title = \"Fourth_Geneva_Convention\"\n",
    "df[df[\"d_properties_title_encode\"] == title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837085fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id d_properties_document_title d_properties_title_encode  \\\n",
      "161  213              Paleomagnetism            Paleomagnetism   \n",
      "\n",
      "                                             cites_ids  \n",
      "161  [1697, 2758, 2723, 1124, 6036, 3414, 2996, 423...  \n",
      "\n",
      "Title 'Paleomagnetism' is in categories:\n",
      "- Historical geology\n",
      "- Geochronological dating methods\n",
      "- Paleomagnetism\n"
     ]
    }
   ],
   "source": [
    "# Find id on df\n",
    "id = 213\n",
    "print(df[df[\"id\"] == id])\n",
    "\n",
    "# Find title on categories\n",
    "title = df[df[\"id\"] == id][\"d_properties_title_encode\"].values[0]\n",
    "cat_from_title = []\n",
    "for cat, titles in category_dict.items():\n",
    "    if title in titles:\n",
    "        cat_from_title.append(cat)\n",
    "\n",
    "# Show categories found\n",
    "print(f\"\\nTitle '{title}' is in categories:\")\n",
    "for cat in cat_from_title:\n",
    "    print(\"-\", cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e0ac1",
   "metadata": {},
   "source": [
    "## 5. Calculate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae96c97",
   "metadata": {},
   "source": [
    "Context: Ground Truth vs. Predicted Communities\n",
    "\n",
    "**Label Mappings**\n",
    "- **Ground truth (X):** Each article ID is mapped to one or more Wikipedia categories (`id_to_cat_multi_label`).\n",
    "- **Predicted (Y):** Each article ID is mapped to a single community label detected by **Leiden** (`id_to_comm`).\n",
    "\n",
    "**Ground Truth Overview - Wikipedia Article Categories**\n",
    "\n",
    "* **Total categories:** `217,562`\n",
    "* **Average categories per article:** `7.33`\n",
    "* **Most frequent category:** *English-language films* (`17,020` articles)\n",
    "* **Article with most categories:** *Fourth Geneva Convention* (`244` categories)\n",
    "\n",
    "**Prediction Overview - Leiden Community Detection**\n",
    "\n",
    "* **Algorithm:** Leiden\n",
    "* **Modularity:** ≈ `0.6`\n",
    "* **Detected communities:** `19`\n",
    "* **Biggest Community:** *C0 - Film, Series, Season, Episodes* (`20,754` articles)\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "We aligned **Wikipedia article categories** (multi-label ground truth) with **Leiden-predicted communities** (single-label prediction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1b2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shared IDs: 107,481\n"
     ]
    }
   ],
   "source": [
    "# --- Extract unique IDs from both sources ---\n",
    "category_ids = set()\n",
    "for ids in category_dict_id.values():\n",
    "    category_ids.update(ids)\n",
    "\n",
    "community_ids = set()\n",
    "for comm in communities:\n",
    "    community_ids.update(comm)\n",
    "\n",
    "# --- Keep only IDs that appear in both ---\n",
    "shared_ids = category_ids & community_ids\n",
    "print(f\"✅ Shared IDs: {len(shared_ids):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "039ebb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build label mappings ---\n",
    "\n",
    "# Map each ID to its category label (X) - \"Ground Truth\"\n",
    "id_to_cat_multi_label  = defaultdict(set)\n",
    "for cat_id_string, ids in category_dict_id.items():\n",
    "    for i in ids:\n",
    "        if i in shared_ids:\n",
    "            id_to_cat_multi_label [i].add(cat_id_string)\n",
    "\n",
    "# Map each ID to its community label (Y) - \"Prediction\"\n",
    "id_to_comm = {}\n",
    "for comm_idx, ids in enumerate(communities):\n",
    "    for i in ids:\n",
    "        if i in shared_ids:\n",
    "            id_to_comm[i] = comm_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e1b64",
   "metadata": {},
   "source": [
    "### Simplify Ground Truth (X) to Single-Label using Dominant Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1c336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index: 0.894868\n",
      "Adjusted Rand Index: 0.041288\n"
     ]
    }
   ],
   "source": [
    "# Precompute category sizes\n",
    "category_sizes = {\n",
    "    cat_id_string: len(ids)\n",
    "    for cat_id_string, ids in category_dict_id.items()\n",
    "}   \n",
    "\n",
    "id_to_cat_single_label = {}\n",
    "for i in shared_ids:\n",
    "    # Get the set of categories this shared ID belongs to\n",
    "    assigned_cats = id_to_cat_multi_label.get(i)\n",
    "\n",
    "    if len(assigned_cats) == 1:\n",
    "        # If no overlap, simply use the single category ID string\n",
    "        id_to_cat_single_label[i] = list(assigned_cats)[0]\n",
    "    else:\n",
    "        # --- DOMINANT CATEGORY SELECTION LOGIC ---\n",
    "        best_cat = None\n",
    "        max_size = -1\n",
    "        \n",
    "        # Iterate over all categories the ID belongs to\n",
    "        for cat_id in assigned_cats:\n",
    "            size = category_sizes[cat_id]\n",
    "            \n",
    "            # If the current category is larger than the best found so far\n",
    "            if size > max_size:\n",
    "                max_size = size\n",
    "                best_cat = cat_id\n",
    "            # Tie-breaking rule: if sizes are equal, use the alphabetically first cat_id\n",
    "            elif size == max_size and cat_id < best_cat:\n",
    "                 best_cat = cat_id\n",
    "        \n",
    "        id_to_cat_single_label[i] = best_cat\n",
    "\n",
    "# --- Align both label vectors ---\n",
    "shared_ids_list = list(shared_ids)\n",
    "labels_X = [id_to_cat_single_label[i] for i in shared_ids_list]\n",
    "labels_Y = [id_to_comm[i] for i in shared_ids_list]\n",
    "\n",
    "# --- Compute Rand Index ---\n",
    "ri = rand_score(labels_X, labels_Y)\n",
    "print(f\"Rand Index: {ri:.6f}\")\n",
    "\n",
    "# --- Compute ARI ---\n",
    "ari = adjusted_rand_score(labels_X, labels_Y)\n",
    "print(f\"Adjusted Rand Index: {ari:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc128d",
   "metadata": {},
   "source": [
    "- A high RI (or ARI) is expected when the number of partitions is small, as is the case here (19 detected communities vs. a simplified ground truth with a likely small number of dominant categories). \n",
    "- It primarily indicates that the Leiden algorithm's partitioning is structurally similar to the simplified, dominant categories, but it masks the complexity of the true multi-label ground truth.\n",
    "\n",
    "- The ARI value being extremely close to zero means the agreement between the detected communities and the ground truth is no better than random chance. \n",
    "- When correcting for the high chance agreement introduced by mapping a massive, detailed, multi-label structure (217K categories) down to just 19 partitions, the clustering provides no meaningful, non-random insight. The algorithm is effectively failing to identify or align with the specific, complex structure hidden within the Wikipedia categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97018c2",
   "metadata": {},
   "source": [
    "### Pairwise Co-membership Evaluation\n",
    "\n",
    "For every pair of IDs `(i, j)`:\n",
    "\n",
    "| Case           | Ground Truth                                                     | \n",
    "| -------------- | ---------------------------------------------------------------- | \n",
    "| **True Positive (TP)**  |`(i, j)` **share** ≥1 true group **and** are in **same** predicted group     |            \n",
    "| **True Negative (TN)**  |`(i, j)` **not** in same predicted group and share **no** true group         |       \n",
    "| **False Positive (FP)** |`(i, j)` in **same** predicted group but share **no** true group         |            \n",
    "| **False Negative (FN)** |`(i, j)` **share** ≥1 true group but are **not** in same predicted group |            \n",
    "\n",
    "- *true group* = same category\n",
    "- *predicted group* = same community\n",
    "\n",
    "Then compute **pairwise precision, recall, and F1**:\n",
    "\n",
    "$$\n",
    "\\text{Rand Index (RI)} = \\frac{TP + TN}{TP + FP + FN + TN}\n",
    "\\quad\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "\\quad\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "\\quad\n",
    "\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f9d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Co-membership Metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# results_raw = calculate_pairwise_metrics(id_to_cat_multi_label, id_to_comm)\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPairwise Co-membership Metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrue Positives (TP): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresults_raw\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mTP\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFalse Positives (FP): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_raw[\u001b[33m'\u001b[39m\u001b[33mFP\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFalse Negatives (FN): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_raw[\u001b[33m'\u001b[39m\u001b[33mFN\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_raw' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_pairwise_metrics(id_to_cat_multi_label, id_to_comm):\n",
    "    \"\"\"\n",
    "    Calculate pairwise co-membership metrics for multi-label true groups and single-label predicted communities.\n",
    "    \n",
    "    Args:\n",
    "        id_to_cat_multi_label: dict mapping ID to set of true categories\n",
    "        id_to_comm: dict mapping ID to predicted community\n",
    "    \n",
    "    Returns:\n",
    "        dict with metrics and counts\n",
    "    \"\"\"\n",
    "    # Get all IDs\n",
    "    all_ids = list(id_to_comm.keys())\n",
    "    n_pairs = len(all_ids) * (len(all_ids) - 1) // 2\n",
    "\n",
    "    print(f\"Total pairs to evaluate: {n_pairs}\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    TP = FP = FN = TN = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate over all unique pairs of IDs\n",
    "    for i in range(len(all_ids)):\n",
    "        for j in range(i + 1, len(all_ids)):\n",
    "            id_i = all_ids[i]\n",
    "            id_j = all_ids[j]\n",
    "            \n",
    "            # Check true group co-membership (share at least one category)\n",
    "            true_co_membership = len(id_to_cat_multi_label[id_i] & id_to_cat_multi_label[id_j]) > 0\n",
    "            \n",
    "            # Check predicted group co-membership (same community)\n",
    "            pred_co_membership = (id_to_comm[id_i] == id_to_comm[id_j])\n",
    "            \n",
    "            # Classify the pair\n",
    "            if true_co_membership and pred_co_membership:\n",
    "                TP += 1\n",
    "            elif (not true_co_membership) and pred_co_membership:\n",
    "                FP += 1\n",
    "            elif true_co_membership and (not pred_co_membership):\n",
    "                FN += 1\n",
    "            else:  # not true_co_membership and not pred_co_membership\n",
    "                TN += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rand_index = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TN': TN,\n",
    "        'total_pairs': TP + FP + FN + TN,\n",
    "        'rand_index': rand_index,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'time_seconds': time.time() - start_time\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "# results_raw = calculate_pairwise_metrics(id_to_cat_multi_label, id_to_comm)\n",
    "\n",
    "print(\"Pairwise Co-membership Metrics:\")\n",
    "print(f\"True Positives (TP): {results_raw['TP']}\")\n",
    "print(f\"False Positives (FP): {results_raw['FP']}\")\n",
    "print(f\"False Negatives (FN): {results_raw['FN']}\")\n",
    "print(f\"True Negatives (TN): {results_raw['TN']}\")\n",
    "print(f\"Total pairs: {results_raw['total_pairs']}\")\n",
    "\n",
    "sum = results_raw['TP'] + results_raw['FP'] + results_raw['FN'] + results_raw['TN']\n",
    "print(f\"\\nSum check (should equal total pairs): {sum} == {results_raw['total_pairs']}\")\n",
    "if sum != results_raw['total_pairs']:\n",
    "    print(\"⚠️ Warning: Sum of TP, FP, FN, TN does not equal total pairs!\")\n",
    "else:\n",
    "    print(\"✅ Sum check passed.\")\n",
    "\n",
    "print(f\"\\nRand Index: {results_raw['rand_index']:.4f}\")\n",
    "print(f\"Precision: {results_raw['precision']:.4f}\")\n",
    "print(f\"Recall: {results_raw['recall']:.4f}\")\n",
    "print(f\"F1 Score: {results_raw['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nComputation Time: {results_raw['time_seconds']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_metrics_efficient(id_to_cat_multi_label, id_to_comm):\n",
    "    \"\"\"\n",
    "    More efficient version that uses community structure to reduce comparisons.\n",
    "    \"\"\"\n",
    "    # Group IDs by predicted community\n",
    "    comm_to_ids = defaultdict(list)\n",
    "    for id_val, comm in id_to_comm.items():\n",
    "        comm_to_ids[comm].append(id_val)\n",
    "    \n",
    "    TP = FP = FN = TN = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Count pairs within same predicted communities\n",
    "    for comm, ids_in_comm in comm_to_ids.items():\n",
    "        n_in_comm = len(ids_in_comm)\n",
    "        if n_in_comm < 2:\n",
    "            continue\n",
    "            \n",
    "        # Count pairs within this community\n",
    "        for i in range(n_in_comm):\n",
    "            for j in range(i + 1, n_in_comm):\n",
    "                id_i = ids_in_comm[i]\n",
    "                id_j = ids_in_comm[j]\n",
    "                \n",
    "                # Check if they share at least one true category\n",
    "                if len(id_to_cat_multi_label[id_i] & id_to_cat_multi_label[id_j]) > 0:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "    \n",
    "    # Count pairs across different communities (FN and TN)\n",
    "    all_communities = list(comm_to_ids.keys())\n",
    "    total_pairs_so_far = TP + FP\n",
    "    \n",
    "    # For FN: pairs that share true categories but are in different predicted communities\n",
    "    # We'll use a different approach for efficiency\n",
    "    \n",
    "    # Create a mapping from category to IDs for efficient lookup\n",
    "    cat_to_ids = defaultdict(set)\n",
    "    for id_val, cats in id_to_cat_multi_label.items():\n",
    "        for cat in cats:\n",
    "            cat_to_ids[cat].add(id_val)\n",
    "    \n",
    "    # Count FN: for each category, count pairs that share this category but are in different communities\n",
    "    fn_counted = set()\n",
    "    for cat, ids_in_cat in cat_to_ids.items():\n",
    "        ids_list = list(ids_in_cat)\n",
    "        for i in range(len(ids_list)):\n",
    "            for j in range(i + 1, len(ids_list)):\n",
    "                id_i, id_j = ids_list[i], ids_list[j]\n",
    "                # Use frozenset to ensure we count each pair only once\n",
    "                pair = frozenset([id_i, id_j])\n",
    "                if pair in fn_counted:\n",
    "                    continue\n",
    "                    \n",
    "                # If they're in different predicted communities\n",
    "                if id_to_comm[id_i] != id_to_comm[id_j]:\n",
    "                    FN += 1\n",
    "                    fn_counted.add(pair)\n",
    "    \n",
    "    # Total possible pairs\n",
    "    n_ids = len(id_to_comm)\n",
    "    total_possible_pairs = n_ids * (n_ids - 1) // 2\n",
    "    \n",
    "    # TN = total pairs - (TP + FP + FN)\n",
    "    TN = total_possible_pairs - (TP + FP + FN)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rand_index = (TP + TN) / total_possible_pairs if total_possible_pairs > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TN': TN,\n",
    "        'total_pairs': total_possible_pairs,\n",
    "        'time_seconds': time.time() - start_time,\n",
    "        'rand_index': rand_index,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Co-membership Metrics:\n",
      "True Positives (TP): 20370689\n",
      "False Positives (FP): 590235997\n",
      "False Negatives (FN): 14028525\n",
      "True Negatives (TN): 5151393729\n",
      "Total pairs: 5776028940\n",
      "\n",
      "Sum check (should equal total pairs): 5776028940 == 5776028940\n",
      "✅ Sum check passed.\n",
      "\n",
      "Rand Index: 0.8954\n",
      "Precision: 0.0334\n",
      "Recall: 0.5922\n",
      "F1 Score: 0.0632\n",
      "\n",
      "Computation Time: 258.80 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "results = calculate_pairwise_metrics_efficient(id_to_cat_multi_label, id_to_comm)\n",
    "\n",
    "print(\"Pairwise Co-membership Metrics:\")\n",
    "print(f\"True Positives (TP): {results['TP']}\")\n",
    "print(f\"False Positives (FP): {results['FP']}\")\n",
    "print(f\"False Negatives (FN): {results['FN']}\")\n",
    "print(f\"True Negatives (TN): {results['TN']}\")\n",
    "print(f\"Total pairs: {results['total_pairs']}\")\n",
    "\n",
    "sum = results['TP'] + results['FP'] + results['FN'] + results['TN']\n",
    "print(f\"\\nSum check (should equal total pairs): {sum} == {results['total_pairs']}\")\n",
    "if sum != results['total_pairs']:\n",
    "    print(\"⚠️ Warning: Sum of TP, FP, FN, TN does not equal total pairs!\")\n",
    "else:\n",
    "    print(\"✅ Sum check passed.\")\n",
    "\n",
    "print(f\"\\nRand Index: {results['rand_index']:.4f}\")\n",
    "print(f\"Precision: {results['precision']:.4f}\")\n",
    "print(f\"Recall: {results['recall']:.4f}\")\n",
    "print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nComputation Time: {results['time_seconds']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66c98d",
   "metadata": {},
   "source": [
    "#### Pair Counts\n",
    "| Count | Value | Contextual Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| **TP** (Same Comm, Shared Cat) | **20.37M** | A decent number of correct intra-community pairs. |\n",
    "| **FP** (Same Comm, **No Shared Cat**) | **590.24M** | **MASSIVE:** This number is $\\mathbf{\\approx 29 \\times}$ larger than TP. This is the **primary problem**; the Leiden algorithm is combining far too many unrelated articles into the same community. This is why Precision is so low. |\n",
    "| **FN** (Diff Comm, **Shared Cat**) | **14.03M** | Lower than TP, indicating that while some related articles are incorrectly separated (low Recall), the algorithm is better at keeping related articles together than it is at keeping unrelated articles apart. |\n",
    "| **TN** (Diff Comm, No Shared Cat) | **5.15B** | **Dominant Factor:** This huge number (over 5 billion) represents the vast majority of all possible pairs. It means most pairs of articles in the dataset share no categories and are correctly separated by Leiden, which inflates the Rand Index. |\n",
    "\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| **Rand Index** | **0.8954** | Again, a high RI (similar to the simplified one). This is dominated by the **True Negatives** (TN) and indicates the Leiden algorithm is **very good at separating pairs of articles that have *nothing* in common** (no shared categories). |\n",
    "| **Precision** | **0.0334** | **Very Low.** When the Leiden algorithm places two articles in the **same community** (Predicted Positive), there is only a **3.34% chance** that those two articles actually share at least one Wikipedia category. This points to **low purity** and significant **False Positives (FP)**. |\n",
    "| **Recall** | **0.5922** | **Moderately Low.** When two articles truly share a category (True Positive + False Negative), the Leiden algorithm correctly places them in the **same community** (True Positive) **59.22%** of the time. This points to moderate **coverage** of the true clusters. |\n",
    "| **F1 Score** | **0.0632** | **Very Low.** This is the harmonic mean of Precision and Recall. The extremely low F1-score is primarily dragged down by the low **Precision**, confirming that the **Leiden communities lack purity** relative to the article categories. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba51e1b",
   "metadata": {},
   "source": [
    "### Pairwise Co-membership Evaluation (Jaccard-weighted)\n",
    "\n",
    "For every pair of IDs `(i, j)`:\n",
    "\n",
    "| Case                    | Ground Truth                                                               | Ground Truth Weight |   Sum Component (Weighted) |                                                                                                                                   \n",
    "| ----------------------- | -------------------------------------------------------------------------- | ------------------------------| --|\n",
    "| **True Positive (TP)**  | `(i, j)` **share** ≥1 true group **and** are in **same** predicted group         | $$\\text{Jaccard}(X_i, X_j)$$ | $$\\sum_{\\text{TP}} \\text{Jaccard}(X_i, X_j)$$ |\n",
    "| **True Negative (TN)**  | `(i, j)` **not** in same predicted group and share **no** true group | $$1 - \\text{Jaccard}(X_i, X_j)$$ |$$\\sum_{\\text{TN}} (1 - 0) = TN$$ |               \n",
    "| **False Positive (FP)**  | `(i, j)` in **same** predicted group but share **no** true group |$$1 - \\text{Jaccard}(X_i, X_j)$$ |$$\\sum_{\\text{TN}} (1 - 0) = FP$$ |    \n",
    "| **False Negative (FN)**  | `(i, j)` **share** ≥1 true group but are **not** in same predicted group | $$\\text{Jaccard}(X_i, X_j)$$ | $$\\sum_{\\text{TP}} \\text{Jaccard}(X_i, X_j)$$ |\n",
    "\n",
    "- *true group* = same category\n",
    "- *predicted group* = same community\n",
    "\n",
    "Then compute a **Weighted Rand Index (RI)**, defined as:\n",
    "\n",
    "$$\n",
    "\\text{WRI} = \\frac{Weighted Agreement}{\\text{Total number of pairs}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\\text{Weighted Agreement} = \\underbrace{\\sum_{\\text{TP}} \\text{Jaccard}(X_i, X_j)}_{\\text{Weighted TP}} + \\underbrace{TN}_{\\text{Weighted TN}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ad63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_pairwise_metrics_weighted(id_to_cat_multi_label, id_to_comm):\n",
    "    \"\"\"\n",
    "    More efficient version that uses community structure to reduce comparisons.\n",
    "    \"\"\"\n",
    "    # Group IDs by predicted community\n",
    "    comm_to_ids = defaultdict(list)\n",
    "    for id_val, comm in id_to_comm.items():\n",
    "        comm_to_ids[comm].append(id_val)\n",
    "    \n",
    "    TP_weighted = TP_count = TN_count_and_weighted = FP_count_and_weighted = FN_weighted = FN_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Count pairs within same predicted communities\n",
    "    for comm, ids_in_comm in comm_to_ids.items():\n",
    "        n_in_comm = len(ids_in_comm)\n",
    "        if n_in_comm < 2:\n",
    "            continue\n",
    "            \n",
    "        # Count pairs within this community\n",
    "        for i in range(n_in_comm):\n",
    "            for j in range(i + 1, n_in_comm):\n",
    "                id_i = ids_in_comm[i]\n",
    "                id_j = ids_in_comm[j]\n",
    "                \n",
    "                # Calculate Jaccard similarity\n",
    "                weight = jaccard_similarity(id_to_cat_multi_label[id_i], id_to_cat_multi_label[id_j])\n",
    "\n",
    "                # Check if they share at least one true category\n",
    "                if len(id_to_cat_multi_label[id_i] & id_to_cat_multi_label[id_j]) > 0:\n",
    "                    TP_weighted += weight\n",
    "                    TP_count += 1\n",
    "                else:\n",
    "                    # FP += 1 - weight, but we count FP as 1 since Jaccard weight is 0\n",
    "                    FP_count_and_weighted += 1\n",
    "    \n",
    "    # Create a mapping from category to IDs for efficient lookup\n",
    "    cat_to_ids = defaultdict(set)\n",
    "    for id_val, cats in id_to_cat_multi_label.items():\n",
    "        for cat in cats:\n",
    "            cat_to_ids[cat].add(id_val)\n",
    "    \n",
    "    # Count FN: for each category, count pairs that share this category but are in different communities\n",
    "    fn_counted = set()\n",
    "    for cat, ids_in_cat in cat_to_ids.items():\n",
    "        ids_list = list(ids_in_cat)\n",
    "        for i in range(len(ids_list)):\n",
    "            for j in range(i + 1, len(ids_list)):\n",
    "                id_i, id_j = ids_list[i], ids_list[j]\n",
    "\n",
    "                # Use frozenset to ensure we count each pair only once\n",
    "                pair = frozenset([id_i, id_j])\n",
    "                if pair in fn_counted:\n",
    "                    continue\n",
    "                    \n",
    "                # If they're in different predicted communities\n",
    "                if id_to_comm[id_i] != id_to_comm[id_j]:\n",
    "                    # Calculate Jaccard similarity\n",
    "                    weight = jaccard_similarity(id_to_cat_multi_label[id_i], id_to_cat_multi_label[id_j])\n",
    "                    FN_weighted += weight\n",
    "                    FN_count += 1\n",
    "                    fn_counted.add(pair)\n",
    "    \n",
    "    # Total possible pairs\n",
    "    n_ids = len(id_to_comm)\n",
    "    total_possible_pairs = n_ids * (n_ids - 1) // 2\n",
    "\n",
    "    # True Negatives (TN) - TN_count is not needed for weighting, since Jaccard weight is 0\n",
    "    TN_count_and_weighted = total_possible_pairs - (TP_count + FP_count_and_weighted + FN_count)\n",
    "\n",
    "    # Total weighted pairs\n",
    "    total_weighted_pairs = TP_weighted + FP_count_and_weighted + FN_weighted + TN_count_and_weighted\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rand_index = (TP_weighted + TN_count_and_weighted) / total_weighted_pairs if total_weighted_pairs > 0 else 0\n",
    "    precision = TP_weighted / (TP_weighted + FP_count_and_weighted) if (TP_weighted + FP_count_and_weighted) > 0 else 0\n",
    "    recall = TP_weighted / (TP_weighted + FN_weighted) if (TP_weighted + FN_weighted) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'TP': TP_weighted,\n",
    "        'FP': FP_count_and_weighted,\n",
    "        'FN': FN_weighted,\n",
    "        'TN': TN_count_and_weighted,\n",
    "        'total_pairs': total_possible_pairs,\n",
    "        'total_weighted_pairs': total_weighted_pairs,\n",
    "        'time_seconds': time.time() - start_time,\n",
    "        'rand_index': rand_index,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcf7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Co-membership Metrics:\n",
      "True Positives (TP): 1402211.4217309589\n",
      "True Negatives (TN): 5151393729\n",
      "False Positives (FP): 590235997\n",
      "False Negatives (FN): 725902.3807737853\n",
      "Total pairs: 5776028940\n",
      "Total weighted pairs: 5743757839.802505\n",
      "\n",
      "Sum check (should equal total pairs): 5743757839.802505 == 5776028940\n",
      "⚠️ Warning: Sum of TP, FP, FN, TN does not equal total pairs!\n",
      "\n",
      "Rand Index: 0.8971\n",
      "Precision: 0.0024\n",
      "Recall: 0.6589\n",
      "F1 Score: 0.0047\n",
      "\n",
      "Computation Time: 675.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "results_weighted = calculate_pairwise_metrics_weighted(id_to_cat_multi_label, id_to_comm)\n",
    "\n",
    "print(\"Pairwise Co-membership Metrics:\")\n",
    "print(f\"True Positives (TP): {results_weighted['TP']}\")\n",
    "print(f\"True Negatives (TN): {results_weighted['TN']}\")\n",
    "print(f\"False Positives (FP): {results_weighted['FP']}\")\n",
    "print(f\"False Negatives (FN): {results_weighted['FN']}\")\n",
    "print(f\"Total pairs: {results_weighted['total_pairs']}\")\n",
    "print(f\"Total weighted pairs: {results_weighted['total_weighted_pairs']}\")\n",
    "\n",
    "sum = results_weighted['TP'] + results_weighted['FP'] + results_weighted['FN'] + results_weighted['TN']\n",
    "print(f\"\\nSum check (should equal total pairs): {sum} == {results_weighted['total_pairs']}\")\n",
    "if sum != results_weighted['total_pairs']:\n",
    "    print(\"⚠️ Warning: Sum of TP, FP, FN, TN does not equal total pairs!\")\n",
    "else:\n",
    "    print(\"✅ Sum check passed.\")\n",
    "\n",
    "print(f\"\\nRand Index: {results_weighted['rand_index']:.4f}\")\n",
    "print(f\"Precision: {results_weighted['precision']:.4f}\")\n",
    "print(f\"Recall: {results_weighted['recall']:.4f}\")\n",
    "print(f\"F1 Score: {results_weighted['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nComputation Time: {results_weighted['time_seconds']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c109165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP difference: -18968477.578269042 (-93.116524%)\n",
      "TN difference: 0 (0.000000%)\n",
      "FP difference: 0 (0.000000%)\n",
      "FN difference: -13302622.619226215 (-94.825526%)\n",
      "Total pairs difference: -32271100.19749546 (-0.558707%)\n",
      "Sum (TP + FN) difference: -32271100.197495256 (-93.813481%)\n",
      "Rand Index difference: 0.0017123233494305001 (0.191236%)\n"
     ]
    }
   ],
   "source": [
    "tp_weighted = results_weighted['TP']\n",
    "tp_raw = 20370689\n",
    "\n",
    "tn_weighted = results_weighted['TN']\n",
    "tn_raw = 5151393729\n",
    "\n",
    "fp_weighted = results_weighted['FP']\n",
    "fp_raw = 590235997\n",
    "\n",
    "fn_weighted = results_weighted['FN']\n",
    "fn_raw = 14028525\n",
    "\n",
    "# Calculate differences\n",
    "tp_diff = tp_weighted - tp_raw\n",
    "tn_diff = tn_weighted - tn_raw\n",
    "fp_diff = fp_weighted - fp_raw\n",
    "fn_diff = fn_weighted - fn_raw\n",
    "\n",
    "print(f\"TP difference: {tp_diff} ({(tp_diff / tp_raw) * 100:.6f}%)\")\n",
    "print(f\"TN difference: {tn_diff} ({(tn_diff / tn_raw) * 100:.6f}%)\")\n",
    "print(f\"FP difference: {fp_diff} ({(fp_diff / fp_raw) * 100:.6f}%)\")\n",
    "print(f\"FN difference: {fn_diff} ({(fn_diff / fn_raw) * 100:.6f}%)\")\n",
    "\n",
    "# Calculate sums differences\n",
    "sum_weighted = tp_weighted + tn_weighted + fp_weighted + fn_weighted\n",
    "sum_raw = tp_raw + tn_raw + fp_raw + fn_raw\n",
    "sum_diff = sum_weighted - sum_raw\n",
    "print(f\"Total pairs difference: {sum_diff} ({(sum_diff / sum_raw) * 100:.6f}%)\")\n",
    "\n",
    "sum_shared_cats_metrics_weighted = tp_weighted + fn_weighted\n",
    "sum_shared_cats_metrics_raw = tp_raw + fn_raw\n",
    "sum_shared_cats_metrics_diff = sum_shared_cats_metrics_weighted - sum_shared_cats_metrics_raw\n",
    "print(f\"Sum (TP + FN) difference: {sum_shared_cats_metrics_diff} ({(sum_shared_cats_metrics_diff / sum_shared_cats_metrics_raw) * 100:.6f}%)\")\n",
    "\n",
    "# Calculate Rand Index differences\n",
    "ri_weighted = results_weighted['rand_index']\n",
    "ri_raw =  0.8954\n",
    "ri_diff = ri_weighted - ri_raw\n",
    "print(f\"Rand Index difference: {ri_diff} ({(ri_diff / ri_raw) * 100:.6f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe18ea9",
   "metadata": {},
   "source": [
    "### Jaccard-Based Similarity Score\n",
    "\n",
    "| **Component**                            | **Definition**                                                                   | **Notes**                                                                  |\n",
    "| ---------------------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| **Ground Truth Sets**                    | *C*<sub>i</sub>: Set of true categories for article *i*.                               | The Ground Truth is **multi-label**.                                       |\n",
    "| **Jaccard Index (J)**                    | $$J(C_i, C_j) = \\dfrac{\\lvert C_i \\cap C_j \\rvert}{\\lvert C_i \\cup C_j \\rvert}$$ | Measures the overlap between category sets *C*<sub>i</sub> and *C*<sub>j</sub>.            |\n",
    "| **Same Pairs (P<sub>same</sub>)** | Pairs `(i, j)` that are in the same predicted community.                 | Includes both **TP** (truly grouped) and **FP** (falsely grouped) pairs. |\n",
    "| **Separated Pairs (P<sub>sep</sub>)** | Pairs `(i, j)` that are **not** in the same predicted community.                 | Includes both **TN** (truly separate) and **FN** (falsely separate) pairs. |\n",
    "\n",
    "\n",
    "New overall evaluation metric, with a custom $\\frac{a+b}{\\text{total}}$, is defined as:\n",
    "\n",
    "$$\\mathbf{Custom\\ Similarity} = \\frac{\\mathbf{a} + \\mathbf{b}}{\\text{Total Number of Pairs}} = \\frac{(\\text{Quality of Grouping}) + (\\text{Quality of Separation})}{\\text{Total Possible Decisions}}$$\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\mathbf{a}$ = $\\sum_{(i, j) \\in \\text{P}_{\\text{Same}}} \\left (J(C_i, C_j)\\right)$.\n",
    "\n",
    "- $\\mathbf{b}$ = $\\sum_{(i, j) \\in \\text{P}_{\\text{Sep}}} \\left(1 - J(C_i, C_j)\\right)$.\n",
    "\n",
    "- $\\text{Total Number of Pairs} = Every\\ possible\\ pair\\ of\\ items = \\frac{n(n-1)}{2}$\n",
    "\n",
    "The term $\\mathbf{a}$ quantifies the **quality of the grouping** for all pairs placed in the **same** predicted community ($\\mathbf{P}_{\\text{Same}}$). Since $J \\in [0, 1]$:\n",
    "\n",
    "- If $J \\approx 0$, the categories are completely disjoint, so $a \\approx 0$. The algorithm is correctly penalized (receives zero reward) for falsely grouping dissimilar pairs.\n",
    "\n",
    "- If $J \\approx 1$, the categories are nearly identical, so $a \\approx 1$. The algorithm is highly rewarded for correctly grouping similar pairs.\n",
    "\n",
    "The term $\\mathbf{b}$ quantifies the **quality of the separation** for all pairs placed in a **different** predicted community ($\\mathbf{P}_{\\text{Sep}}$). Since $J \\in [0, 1]$:\n",
    "\n",
    "- If $J \\approx 0$, the categories are completely disjoint, so $1-J \\approx 1$. The algorithm is highly rewarded for separating this pair.\n",
    "\n",
    "- If $J \\approx 1$, the categories are nearly identical, so $1-J \\approx 0$. The algorithm is penalized (receives no score) for separating this pair, as they should have been together ($\\text{FN}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddebfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def calculate_jaccard_custom_similarity(id_to_cat_multi_label, id_to_comm):\n",
    "    \"\"\"\n",
    "    Calculate pairwise co-membership metrics for multi-label true groups and single-label predicted communities.\n",
    "    \n",
    "    Args:\n",
    "        id_to_cat_multi_label: dict mapping ID to set of true categories\n",
    "        id_to_comm: dict mapping ID to predicted community\n",
    "    \n",
    "    Returns:\n",
    "        dict with metrics and counts\n",
    "    \"\"\"\n",
    "    # Get all IDs\n",
    "    all_ids = list(id_to_comm.keys())\n",
    "    total_possible_pairs = len(all_ids) * (len(all_ids) - 1) // 2\n",
    "\n",
    "    print(f\"Total pairs to evaluate: {total_possible_pairs}\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    a = b = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate over all unique pairs of IDs\n",
    "    for i in range(len(all_ids)):\n",
    "        for j in range(i + 1, len(all_ids)):\n",
    "            id_i = all_ids[i]\n",
    "            id_j = all_ids[j]\n",
    "            \n",
    "            # Check predicted group co-membership (same community)\n",
    "            pred_co_membership = (id_to_comm[id_i] == id_to_comm[id_j])\n",
    "\n",
    "            # Calculate Jaccard similarity\n",
    "            weight = jaccard_similarity(id_to_cat_multi_label[id_i], id_to_cat_multi_label[id_j])\n",
    "            \n",
    "            # Classify the pair\n",
    "            if pred_co_membership:\n",
    "                a += weight\n",
    "            else:\n",
    "                b += (1 - weight)\n",
    "    \n",
    "    # Total sum of weights\n",
    "    total_weighted_pairs = a + b\n",
    "\n",
    "    # Jaccard Based Similarity Score\n",
    "    jaccard_similarity_score = total_weighted_pairs / total_possible_pairs if total_possible_pairs > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_possible_pairs': total_possible_pairs,\n",
    "        'a_quality_grouping': a,\n",
    "        'b_quality_separation': b,\n",
    "        'total_weighted_pairs': total_weighted_pairs,\n",
    "        'jaccard_similarity_score': jaccard_similarity_score,\n",
    "        'time_seconds': time.time() - start_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc819746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs to evaluate: 5776028940\n",
      "Pairwise Co-membership Metrics:\n",
      "Quality of Grouping (a): 1402211.4217309589\n",
      "Quality of Separation (b): 5164696351.643766\n",
      "Total possible pairs: 5776028940\n",
      "Total weighted pairs: 5166098563.065497\n",
      "\n",
      "Jaccard Similarity Score: 0.8944\n",
      "\n",
      "Computation Time: 5790.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "results_jaccard = calculate_jaccard_custom_similarity(id_to_cat_multi_label, id_to_comm)\n",
    "\n",
    "print(\"Pairwise Co-membership Metrics:\")\n",
    "print(f\"Quality of Grouping (a): {results_jaccard['a_quality_grouping']}\")\n",
    "print(f\"Quality of Separation (b): {results_jaccard['b_quality_separation']}\")\n",
    "print(f\"Total possible pairs: {results_jaccard['total_possible_pairs']}\")\n",
    "print(f\"Total weighted pairs: {results_jaccard['total_weighted_pairs']}\")\n",
    "\n",
    "print(f\"\\nJaccard Similarity Score: {results_jaccard['jaccard_similarity_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nComputation Time: {results_jaccard['time_seconds']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b323f68",
   "metadata": {},
   "source": [
    "### Normalized Jaccard-Based Similarity\n",
    "\n",
    "We'll define the new metrics by first counting the number of pairs that contribute to the $\\mathbf{a}$ and $\\mathbf{b}$ terms, which are $\\mathbf{P}_{\\text{Same}}$ and $\\mathbf{P}_{\\text{Sep}}$, respectively.\n",
    "\n",
    "**1. Pair Counts**\n",
    "\n",
    "| **Component**                            | **Definition**                                                                   | **Formula**                                                                  |\n",
    "| :--------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- |\n",
    "| **Same Pair Count ($\\mathbf{N}_{\\text{Same}}$)** | The total number of pairs $(i, j)$ in the same predicted community ($\\mathbf{P}_{\\text{Same}}$). | $$\\mathbf{N}_{\\text{Same}} = \\lvert \\mathbf{P}_{\\text{Same}} \\rvert$$                                                         |\n",
    "| **Separated Pair Count ($\\mathbf{N}_{\\text{Sep}}$)** | The total number of pairs $(i, j)$ **not** in the same predicted community ($\\mathbf{P}_{\\text{Sep}}$). | $$\\mathbf{N}_{\\text{Sep}} = \\lvert \\mathbf{P}_{\\text{Sep}} \\rvert$$                                                         |\n",
    "\n",
    "**Note**: The sum of these counts must equal the total number of pairs:\n",
    "$$\\mathbf{N}_{\\text{Same}} + \\mathbf{N}_{\\text{Sep}} = \\frac{n(n-1)}{2}$$\n",
    "\n",
    "---\n",
    "\n",
    "**2. Average Grouping Quality ($\\mathbf{A_G}$)**\n",
    "\n",
    "This metric normalizes the total grouping quality ($\\mathbf{a}$) by the number of pairs that were grouped ($\\mathbf{N}_{\\text{Same}}$). It represents the **average Jaccard Index** for all pairs placed together.\n",
    "\n",
    "| **Component**                            | **Definition**                                                                   | **Formula**                                                                  |\n",
    "| :--------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- |\n",
    "| **Average Grouping Quality ($\\mathbf{A_G}$)** | The average Jaccard Index for all $\\mathbf{P}_{\\text{Same}}$ pairs.                                             | $$\\mathbf{A_G} = \\frac{\\mathbf{a}}{\\mathbf{N}_{\\text{Same}}} = \\frac{1}{\\mathbf{N}_{\\text{Same}}} \\sum_{(i, j) \\in \\mathbf{P}_{\\text{Same}}} J(C_i, C_j)$$ |\n",
    "\n",
    "**Interpretation**:\n",
    "- $A_G \\approx 1$ means the algorithm's groupings are highly accurate; grouped pairs have very similar true categories.\n",
    "- $A_G \\approx 0$ means the algorithm is often grouping completely dissimilar pairs.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Average Separation Quality ($\\mathbf{A_S}$)**\n",
    "\n",
    "This metric normalizes the total separation quality ($\\mathbf{b}$) by the number of pairs that were separated ($\\mathbf{N}_{\\text{Sep}}$). It represents the **average dissimilarity ($1-J$)** for all pairs placed in different communities.\n",
    "\n",
    "| **Component**                            | **Definition**                                                                   | **Formula**                                                                  |\n",
    "| :--------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- |\n",
    "| **Average Separation Quality ($\\mathbf{A_S}$)** | The average dissimilarity $(1-J)$ for all $\\mathbf{P}_{\\text{Sep}}$ pairs.                                             | $$\\mathbf{A_S} = \\frac{\\mathbf{b}}{\\mathbf{N}_{\\text{Sep}}} = \\frac{1}{\\mathbf{N}_{\\text{Sep}}} \\sum_{(i, j) \\in \\mathbf{P}_{\\text{Sep}}} \\left(1 - J(C_i, C_j)\\right)$$ |\n",
    "\n",
    "**Interpretation**:\n",
    "- $A_S \\approx 1$ means the algorithm's separations are highly accurate; separated pairs have very dissimilar true categories.\n",
    "- $A_S \\approx 0$ means the algorithm is often separating pairs that are highly similar (many False Negatives).\n",
    "\n",
    "---\n",
    "\n",
    "**4. Jaccard-Based Average Similarity Score ($\\mathbf{S_{Avg}}$)**\n",
    "\n",
    "This is the final overall score, calculated as the simple average of the **Average Grouping Quality ($A_G$)** and the **Average Separation Quality ($A_S$)**.\n",
    "\n",
    "| **Component**                            | **Definition**                                                                   | **Formula**                                                                  |\n",
    "| :--------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- |\n",
    "| **Jaccard-Based Average Similarity Score ($\\mathbf{S_{Avg}}$)** | The balanced overall score, averaging the quality of grouping and separation.                                             | $$\\mathbf{S_{Avg}} = \\frac{\\mathbf{A_G} + \\mathbf{A_S}}{2}$$ |\n",
    "\n",
    "**Key Feature**: This metric treats the grouping decisions ($\\mathbf{P}_{\\text{Same}}$) and separation decisions ($\\mathbf{P}_{\\text{Sep}}$) as equally important, irrespective of their sample size ($\\mathbf{N}_{\\text{Same}}$ vs. $\\mathbf{N}_{\\text{Sep}}$). It directly gives the average reward earned per grouping decision and per separation decision, then averages those two averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c7a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Grouping Quality: 0.002296\n",
      "Average Separation Quality: 0.999859\n",
      "Overall Quality Ratio: 0.501078\n"
     ]
    }
   ],
   "source": [
    "# 'a' and 'b' values - sum of weights based on Jaccard similarity\n",
    "a = 1402211.4217309589  # Quality of Grouping - total sum\n",
    "b = 5164696351.643766   # Quality of Separation - total sum\n",
    "\n",
    "# Counts - number of pairs fitting each category\n",
    "same_pair_count = 20370689 + 590235997       # TP + FP - pairs in same predicted community\n",
    "dif_pair_count = 5151393729 + 14028525       # TN + FN - pairs in different predicted communities\n",
    "\n",
    "# Calculate ratios\n",
    "a_ratio = a / same_pair_count\n",
    "print(f\"Average Grouping Quality: {a_ratio:4f}\")\n",
    "b_ratio = b / dif_pair_count\n",
    "print(f\"Average Separation Quality: {b_ratio:4f}\")\n",
    "\n",
    "overall_ratio = (a_ratio + b_ratio) / 2\n",
    "print(f\"Overall Quality Ratio: {overall_ratio:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01784102",
   "metadata": {},
   "source": [
    "- Quality of Grouping (a): 1,402,211.4\n",
    "- Quality of Separation (b): 5,164,696,351.6\n",
    "\n",
    "- Total weighted pairs: 5,166,098,563.1\n",
    "\n",
    "- Total possible pairs: 5,776,028,940\n",
    "\n",
    "- Jaccard Similarity Score: 0.8944\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d6770",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg4ai-community-detection-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
