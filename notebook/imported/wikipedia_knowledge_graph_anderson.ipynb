{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd603bc0",
   "metadata": {},
   "source": [
    "# Wikipedia Knowledge Graph Builder - Anderson Database\n",
    "\n",
    "This notebook creates a knowledge graph from Wikipedia pages by importing JSON data into a Neo4j database.\n",
    "The data contains Wikipedia entities with their titles, URLs, and relationships to other entities.\n",
    "\n",
    "**Database:** anderson (instead of matheus)\n",
    "**Features:** Includes comprehensive test queries to verify database connectivity and data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9c63d",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "First, let's install the necessary libraries in our virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ac2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (5.28.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: groq in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mathe\\onedrive\\√°rea de trabalho\\ic\\kg4ai\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install neo4j pandas groq\n",
    "\n",
    "import logging\n",
    "\n",
    "# Option 1: Silence httpx completely\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe36d44",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup\n",
    "\n",
    "Import the necessary libraries for data processing and Neo4j connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28a93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec19684",
   "metadata": {},
   "source": [
    "## 3. Configure Neo4j Connection\n",
    "\n",
    "Set up the connection parameters for the Neo4j database.\n",
    "**Note:** This connects to the 'anderson' database instead of 'matheus'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92cc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Neo4j connection details from environment variables\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "MY_GROQ_API_KEY = os.getenv(\"MY_GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b2d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to Neo4j database: anderson!\n"
     ]
    }
   ],
   "source": [
    "NEO4J_DATABASE = \"anderson\"  # Changed from 'matheus' to 'anderson'\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    driver.verify_connectivity()\n",
    "    print(f\"‚úÖ Successfully connected to Neo4j database: {NEO4J_DATABASE}!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to connect to Neo4j: {e}\")\n",
    "    print(\"Please check your connection parameters and network access.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8f773",
   "metadata": {},
   "source": [
    "## 4. Database Connection Tests\n",
    "\n",
    "Run comprehensive tests to verify the database connection and basic functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb1bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running connection tests for database: anderson\n",
      "============================================================\n",
      "\n",
      "üîç Node Count:\n",
      "   {'total_nodes': 108071}\n",
      "   ‚úÖ PASSED\n",
      "\n",
      "üîç Relationship Count:\n",
      "   {'total_relationships': 5122983}\n",
      "   ‚úÖ PASSED\n",
      "\n",
      "üîç Node Examples:\n",
      "   {'n': <Node element_id='4:272e7fb9-be88-49e0-938d-4859e141ff40:0' labels=frozenset({'Document'}) properties={'document_title': 'Therefore sign', 'title_encode': 'Therefore_sign', 'document_url': 'https://en.wikipedia.org//w/index.php?title=Therefore_sign&amp;oldid=815234923'}>}\n",
      "   {'n': <Node element_id='4:272e7fb9-be88-49e0-938d-4859e141ff40:1' labels=frozenset({'Document'}) properties={'document_title': 'Watchman (law enforcement)', 'title_encode': 'Watchman_(law_enforcement)', 'document_url': 'https://en.wikipedia.org//w/index.php?title=Watchman_(law_enforcement)&amp;oldid=807971712'}>}\n",
      "   {'n': <Node element_id='4:272e7fb9-be88-49e0-938d-4859e141ff40:3' labels=frozenset({'Document'}) properties={'document_title': 'Super Bowl 50 halftime show', 'title_encode': 'Super_Bowl_50_halftime_show', 'document_url': 'https://en.wikipedia.org//w/index.php?title=Super_Bowl_50_halftime_show&amp;oldid=823813276'}>}\n",
      "   ‚úÖ PASSED\n",
      "\n",
      "üîç Relationship Examples:\n",
      "   {'p': <Path start=<Node element_id='4:272e7fb9-be88-49e0-938d-4859e141ff40:0' labels=frozenset({'Document'}) properties={'document_title': 'Therefore sign', 'title_encode': 'Therefore_sign', 'document_url': 'https://en.wikipedia.org//w/index.php?title=Therefore_sign&amp;oldid=815234923'}> end=<Node element_id='4:272e7fb9-be88-49e0-938d-4859e141ff40:6352' labels=frozenset({'Document'}) properties={'document_title': 'At sign', 'title_encode': 'At_sign', 'document_url': 'https://en.wikipedia.org//w/index.php?title=At_sign&amp;oldid=807053367'}> size=1>}\n",
      "   ‚úÖ PASSED\n",
      "\n",
      "============================================================\n",
      "üéØ Connection tests completed!\n"
     ]
    }
   ],
   "source": [
    "def run_connection_tests(driver):\n",
    "    \"\"\"\n",
    "    Run comprehensive tests to verify database connectivity and basic functionality.\n",
    "    \"\"\"\n",
    "    tests = {\n",
    "        \"Node Count\": \"MATCH (n) RETURN count(n) as total_nodes\",\n",
    "        \"Relationship Count\": \"MATCH ()-[r]->() RETURN count(r) as total_relationships\",\n",
    "        \"Node Examples\": \"MATCH (n) RETURN n LIMIT 3\",\n",
    "        \"Relationship Examples\": \"MATCH p=()-->() RETURN p LIMIT 1\"\n",
    "\n",
    "    }\n",
    "    \n",
    "    print(f\"üß™ Running connection tests for database: {NEO4J_DATABASE}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        for test_name, query in tests.items():\n",
    "            try:\n",
    "                print(f\"\\nüîç {test_name}:\")\n",
    "                result = session.run(query)\n",
    "                records = list(result)\n",
    "                \n",
    "                if records:\n",
    "                    for record in records:\n",
    "                        print(f\"   {dict(record)}\")\n",
    "                else:\n",
    "                    print(\"   No results returned\")\n",
    "                    \n",
    "                print(\"   ‚úÖ PASSED\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå FAILED: {e}\")\n",
    "                \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üéØ Connection tests completed!\")\n",
    "\n",
    "# Run connection tests\n",
    "run_connection_tests(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b85618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Groq API: **Neo4j** is a popular, open-source, graph database management system. It is designed to store and manage large amounts of graph data in an efficient and scalable manner.\n",
      "\n",
      "### What is a Graph Database?\n",
      "\n",
      "A graph database is a type of NoSQL database that stores data as a collection of nodes or vertices connected by edges. Each node represents an entity, and each edge represents a relationship between two entities. This structure allows for efficient querying and navigating of complex relationships between data entities.\n",
      "\n",
      "### Key Features of Neo4j\n",
      "\n",
      "1. **Graph Data Model**: Neo4j uses a native graph data model, allowing it to efficiently store and query graph data.\n",
      "2. **ACID Compliance**: Neo4j supports Atomicity, Consistency, Isolation, and Durability (ACID) transactions, ensuring that database operations are executed reliably and safely.\n",
      "3. **Schema-Agnostic**: Neo4j has a schema-agnostic design, allowing you to model your data without the need for a predefined schema.\n",
      "4. **High-Performance**: Neo4j is optimized for high-performance querying and data retrieval, making it suitable for real-time applications and large-scale datasets.\n",
      "5. **Scalability**: Neo4j supports horizontal scaling, allowing it to handle large volumes of data and high traffic with ease.\n",
      "\n",
      "### Use Cases for Neo4j\n",
      "\n",
      "1. **Social Network Analysis**: Neo4j is well-suited for modeling and analyzing social networks, where users are connected by relationships such as friendships, followers, or likes.\n",
      "2. **Recommendation Systems**: Neo4j can be used to build recommendation systems that take into account complex relationships between users and items.\n",
      "3. **Knowledge Graphs**: Neo4j is ideal for storing and querying large knowledge graphs that contain entities, relationships, and attributes.\n",
      "4. **Cybersecurity**: Neo4j can be used to analyze complex networks and relationships between entities, such as devices, users, and connections.\n",
      "5. **Log Analysis**: Neo4j can be used to analyze and process large logs, where relationships between events and entities need to be understood.\n",
      "\n",
      "### Example Use Case: Social Network Analysis\n",
      "\n",
      "Suppose we want to analyze a social network where users are connected by friendships. We can create nodes for users and relationships for friendships, as follows:\n",
      "\n",
      "```cypher\n",
      "// Create nodes for users\n",
      "CREATE (alice:User {name: 'Alice'})\n",
      "CREATE (bob:User {name: 'Bob'})\n",
      "CREATE (charlie:User {name: 'Charlie'})\n",
      "\n",
      "// Create relationships between users\n",
      "CREATE (alice)-[:FRIEND_OF {since: 2018}]->(bob)\n",
      "CREATE (bob)-[:FRIEND_OF {since: 2019}]->(charlie)\n",
      "```\n",
      "\n",
      "In this example, we create nodes for users Alice, Bob, and Charlie, and then establish relationships between them through FRIEND_OF relationships. We can then query the network to find out who is friends with whom, or who are mutual friends.\n",
      "\n",
      "```cypher\n",
      "// Find mutual friends\n",
      "MATCH (a:User {name: 'Alice'})-[:FRIEND_OF*2]-(b:User)\n",
      "RETURN b.name AS name\n",
      "```\n",
      "\n",
      "In this query, we find all users who are friends of Alice and are also friends of one of Alice's friends.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Neo4j is a powerful graph database management system that is well-suited for modeling and analyzing complex relationships between data entities. Its scalability, high-performance querying, and schema-agnostic design make it an ideal choice for a wide range of use cases, including social network analysis, recommendation systems, knowledge graphs, cybersecurity, and log analysis.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=MY_GROQ_API_KEY)\n",
    "# MODEL = \"llama-3.3-70b-versatile\"\n",
    "MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "def ask_LLM(question: str, model: str=MODEL) -> str:\n",
    "    \"\"\"\n",
    "    Queries the Groq API with a question and model.\n",
    "\n",
    "    Args:\n",
    "        question (str): The input question for the model.\n",
    "        model (str): The model to query.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the model as a string or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": question}],\n",
    "            model=model,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Groq API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "response = ask_LLM(\"What is Neo4j?\")\n",
    "print(\"Response from Groq API:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f26b5",
   "metadata": {},
   "source": [
    "## 5. LLM-Guided Graph Search Algorithm\n",
    "\n",
    "Implementation of a sophisticated graph search algorithm that uses LLM guidance for entity extraction, path pruning, and sufficiency checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44407c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the relationship between Albert Einstein and the theory of relativity?\n",
      "Extracted entities: ['Albert Einstein', 'theory of relativity']\n"
     ]
    }
   ],
   "source": [
    "def llm_extract_entities(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract relevant entities from a query using LLM.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input query\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of extracted entities\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract the main entities (people, places, concepts, organizations) from this query.\n",
    "    Return only the entity names, one per line, without any additional text or formatting.\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Entities:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ask_LLM(prompt)\n",
    "    if not response:\n",
    "        return []\n",
    "    \n",
    "    # Parse entities from response\n",
    "    entities = [entity.strip() for entity in response.split('\\n') if entity.strip()]\n",
    "    return entities\n",
    "\n",
    "# Test the function\n",
    "test_query = \"What is the relationship between Albert Einstein and the theory of relativity?\"\n",
    "extracted_entities = llm_extract_entities(test_query)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Extracted entities: {extracted_entities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4050a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: ['Einstein', 'relativity']\n",
      "Found 5 similar nodes:\n",
      "  1. Einstein‚ÄìSzil√°rd letter (matched: Einstein)\n",
      "  2. Theory of relativity (matched: relativity)\n",
      "  3. Religious and philosophical views of Albert Einstein (matched: Einstein)\n",
      "  4. General relativity (matched: relativity)\n",
      "  5. Einstein field equations (matched: Einstein)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def find_similar_nodes(entities: List[str], top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Find nodes in the knowledge graph that match the extracted entities.\n",
    "    Uses simple string matching for now (can be improved with embeddings later).\n",
    "    \n",
    "    Args:\n",
    "        entities (List[str]): List of entity names to search for\n",
    "        top_k (int): Number of top nodes to return\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: List of matching nodes with their properties\n",
    "    \"\"\"\n",
    "    # Reconnect to the database\n",
    "    driver_local = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    \n",
    "    matching_nodes = []\n",
    "    \n",
    "    with driver_local.session(database=NEO4J_DATABASE) as session:\n",
    "        for entity in entities:\n",
    "            # Search for nodes with title containing the entity (case-insensitive)\n",
    "            query = \"\"\"\n",
    "            MATCH (n)\n",
    "            WHERE toLower(n.document_title) CONTAINS toLower($entity)\n",
    "            RETURN n.document_title as title, n.document_url as url, n\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "            \n",
    "            result = session.run(query, entity=entity, limit=top_k)\n",
    "            for record in result:\n",
    "                node_data = {\n",
    "                    'title': record['title'],\n",
    "                    'url': record['url'],\n",
    "                    'node': record['n'],\n",
    "                    'search_entity': entity\n",
    "                }\n",
    "                matching_nodes.append(node_data)\n",
    "    \n",
    "    driver_local.close()\n",
    "    \n",
    "    # Return top_k unique nodes (remove duplicates)\n",
    "    seen_titles = set()\n",
    "    unique_nodes = []\n",
    "    for node in matching_nodes:\n",
    "        if node['title'] not in seen_titles:\n",
    "            seen_titles.add(node['title'])\n",
    "            unique_nodes.append(node)\n",
    "    \n",
    "    # randomly select top_k nodes if more than top_k found\n",
    "    if len(unique_nodes) > top_k:\n",
    "        unique_nodes = random.sample(unique_nodes, top_k)\n",
    "    \n",
    "    return unique_nodes\n",
    "\n",
    "# Test the function\n",
    "test_entities = [\"Einstein\", \"relativity\"]\n",
    "similar_nodes = find_similar_nodes(test_entities, top_k=5)\n",
    "print(f\"Entities: {test_entities}\")\n",
    "print(f\"Found {len(similar_nodes)} similar nodes:\")\n",
    "for i, node in enumerate(similar_nodes, 1):\n",
    "    print(f\"  {i}. {node['title']} (matched: {node['search_entity']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f69dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 2 paths:\n",
      "  Path 1: ['Test Node 1']\n",
      "  Path 2: ['Test Node 2']\n",
      "\n",
      "Expanded to 10 paths:\n",
      "  Path 1: Einstein‚ÄìSzil√°rd letter -> [CITES] -> Uranium-238\n",
      "  Path 2: Einstein‚ÄìSzil√°rd letter <- [CITES] <- History of nuclear weapons\n",
      "  Path 3: Theory of relativity -> [CITES] -> Force\n",
      "  Path 4: Theory of relativity <- [CITES] <- Viscosity\n",
      "  Path 5: Religious and philosophical views of Albert Einstein -> [CITES] -> Causality\n",
      "  Path 6: Religious and philosophical views of Albert Einstein <- [CITES] <- Brownian motion\n",
      "  Path 7: General relativity -> [CITES] -> Angular momentum\n",
      "  Path 8: General relativity <- [CITES] <- Earth science\n",
      "  Path 9: Einstein field equations -> [CITES] -> Black hole\n",
      "  Path 10: Einstein field equations <- [CITES] <- Timeline of quantum mechanics\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def initialize_paths(initial_nodes: List[Dict]) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Initialize paths with the retrieved initial nodes.\n",
    "    \n",
    "    Args:\n",
    "        initial_nodes (List[Dict]): List of initial nodes\n",
    "        \n",
    "    Returns:\n",
    "        List[List[Dict]]: List of paths, each containing one initial node\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for node in initial_nodes:\n",
    "        path = [{'title': node['title'], 'url': node['url'], 'type': 'node'}]\n",
    "        paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def expand_paths(paths: List[List[Dict]], max_neighbors: int = 5) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Expand each path by one hop, finding successors and predecessors.\n",
    "    \n",
    "    Args:\n",
    "        paths (List[List[Dict]]): Current paths\n",
    "        max_neighbors (int): Maximum neighbors to explore per node\n",
    "        \n",
    "    Returns:\n",
    "        List[List[Dict]]: Expanded paths\n",
    "    \"\"\"\n",
    "    driver_local = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    expanded_paths = []\n",
    "    \n",
    "    with driver_local.session(database=NEO4J_DATABASE) as session:\n",
    "        for path in paths:\n",
    "            last_node = path[-1]\n",
    "            last_node_title = last_node['title']\n",
    "            \n",
    "            # Get nodes already in the path to avoid cycles\n",
    "            path_titles = {node['title'] for node in path if node['type'] == 'node'}\n",
    "            \n",
    "            # Find outgoing relationships\n",
    "            query_out = \"\"\"\n",
    "            MATCH (a {document_title: $title})-[r]->(b)\n",
    "            WHERE NOT b.document_title IN $path_titles\n",
    "            RETURN type(r) as rel_type, b.document_title as target_title, b.document_url as target_url\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "            \n",
    "            # Find incoming relationships\n",
    "            query_in = \"\"\"\n",
    "            MATCH (a)-[r]->(b {document_title: $title})\n",
    "            WHERE NOT a.document_title IN $path_titles\n",
    "            RETURN type(r) as rel_type, a.document_title as source_title, a.document_url as source_url\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "            \n",
    "            # Execute outgoing relationships\n",
    "            result_out = session.run(query_out, title=last_node_title, \n",
    "                                   path_titles=list(path_titles), limit=1000)\n",
    "            \n",
    "            # Randomly sample max_neighbors from result_out\n",
    "            result_out = list(result_out)\n",
    "            if len(result_out) > max_neighbors:\n",
    "                result_out = random.sample(result_out, math.ceil(max_neighbors / 2))\n",
    "\n",
    "            for record in result_out:\n",
    "                new_path = path.copy()\n",
    "                new_path.append({\n",
    "                    'type': 'relationship',\n",
    "                    'rel_type': record['rel_type'],\n",
    "                    'direction': 'outgoing'\n",
    "                })\n",
    "                new_path.append({\n",
    "                    'type': 'node',\n",
    "                    'title': record['target_title'],\n",
    "                    'url': record['target_url']\n",
    "                })\n",
    "                expanded_paths.append(new_path)\n",
    "            \n",
    "            # Execute incoming relationships\n",
    "            result_in = session.run(query_in, title=last_node_title, \n",
    "                                  path_titles=list(path_titles), limit=1000)\n",
    "            result_in = list(result_in)\n",
    "            if len(result_in) > max_neighbors:\n",
    "                result_in = random.sample(result_in, math.floor(max_neighbors / 2))\n",
    "\n",
    "            for record in result_in:\n",
    "                new_path = path.copy()\n",
    "                new_path.append({\n",
    "                    'type': 'relationship',\n",
    "                    'rel_type': record['rel_type'],\n",
    "                    'direction': 'incoming'\n",
    "                })\n",
    "                new_path.append({\n",
    "                    'type': 'node',\n",
    "                    'title': record['source_title'],\n",
    "                    'url': record['source_url']\n",
    "                })\n",
    "                expanded_paths.append(new_path)\n",
    "    \n",
    "    driver_local.close()\n",
    "    return expanded_paths if expanded_paths else paths\n",
    "\n",
    "# Test path initialization and expansion\n",
    "test_nodes = [{'title': 'Test Node 1', 'url': 'url1'}, {'title': 'Test Node 2', 'url': 'url2'}]\n",
    "initial_paths = initialize_paths(test_nodes)\n",
    "print(f\"Initialized {len(initial_paths)} paths:\")\n",
    "for i, path in enumerate(initial_paths, 1):\n",
    "    print(f\"  Path {i}: {[node['title'] for node in path if node['type'] == 'node']}\")\n",
    "\n",
    "# Test with real nodes (if we found any)\n",
    "if similar_nodes:\n",
    "    real_paths = initialize_paths(similar_nodes)\n",
    "    expanded = expand_paths(real_paths, max_neighbors=2)\n",
    "\n",
    "    print(f\"\\nExpanded to {len(expanded)} paths:\")\n",
    "    for i, path in enumerate(expanded, 1):  # Show first 3 paths\n",
    "        if path[1]['direction'] == 'outgoing':\n",
    "            direction = \"->\"\n",
    "        else:\n",
    "            direction = \"<-\"\n",
    "        path_str = \" {} \".format(direction).join([\n",
    "            item['title'] if item['type'] == 'node' \n",
    "            else f\"[{item['rel_type']}]\" \n",
    "            for item in path\n",
    "        ])\n",
    "        print(f\"  Path {i}: {path_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8b3207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test path triples: ['(Albert Einstein) -[DEVELOPED]-> (Theory of Relativity)']\n",
      "Relevance score for 'What did Einstein develop?': 1.0\n"
     ]
    }
   ],
   "source": [
    "def extract_path_triples(path: List[Dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract triples from a path representation.\n",
    "    \n",
    "    Args:\n",
    "        path (List[Dict]): Path containing nodes and relationships\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of triples in string format\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    \n",
    "    for i in range(0, len(path) - 2, 2):  # Step by 2 to get node-rel-node patterns\n",
    "        if (i + 2 < len(path) and \n",
    "            path[i]['type'] == 'node' and \n",
    "            path[i + 1]['type'] == 'relationship' and \n",
    "            path[i + 2]['type'] == 'node'):\n",
    "            \n",
    "            source = path[i]['title']\n",
    "            relation = path[i + 1]['rel_type']\n",
    "            target = path[i + 2]['title']\n",
    "            direction = path[i + 1]['direction']\n",
    "            \n",
    "            if direction == 'outgoing':\n",
    "                triple = f\"({source}) -[{relation}]-> ({target})\"\n",
    "            else:\n",
    "                triple = f\"({target}) -[{relation}]-> ({source})\"\n",
    "            \n",
    "            triples.append(triple)\n",
    "    \n",
    "    return triples\n",
    "\n",
    "def llm_score_path_relevance(query: str, path_triples: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Score the relevance of a path to the query using LLM.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query\n",
    "        path_triples (List[str]): List of triples from the path\n",
    "        \n",
    "    Returns:\n",
    "        float: Relevance score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not path_triples:\n",
    "        return 0.0\n",
    "    \n",
    "    triples_text = \"\\n\".join(path_triples)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Rate the relevance of these knowledge graph triples to answering the given query.\n",
    "    Return only a number between 0 and 1, where:\n",
    "    - 0 = completely irrelevant\n",
    "    - 1 = highly relevant and useful for answering the query\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Triples:\n",
    "    {triples_text}\n",
    "    \n",
    "    Relevance score:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ask_LLM(prompt)\n",
    "    if not response:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        # Extract number from response\n",
    "        score_str = response.strip().split()[0]\n",
    "        score = float(score_str)\n",
    "        return max(0.0, min(1.0, score))  # Clamp between 0 and 1\n",
    "    except (ValueError, IndexError):\n",
    "        return 0.0\n",
    "\n",
    "def prune_paths(query: str, paths: List[List[Dict]], top_n_paths: int = 5) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Prune paths by scoring their relevance and keeping only the top N.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query\n",
    "        paths (List[List[Dict]]): List of paths to prune\n",
    "        top_n_paths (int): Number of top paths to keep\n",
    "        \n",
    "    Returns:\n",
    "        List[List[Dict]]: Pruned paths sorted by relevance\n",
    "    \"\"\"\n",
    "    if not paths:\n",
    "        return []\n",
    "    \n",
    "    scored_paths = []\n",
    "    \n",
    "    for path in paths:\n",
    "        triples = extract_path_triples(path)\n",
    "        score = llm_score_path_relevance(query, triples)\n",
    "        scored_paths.append((score, path))\n",
    "    \n",
    "    # Sort by score (descending) and return top N\n",
    "    scored_paths.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [path for score, path in scored_paths[:top_n_paths]]\n",
    "\n",
    "# Test triple extraction\n",
    "test_path = [\n",
    "    {'type': 'node', 'title': 'Albert Einstein'},\n",
    "    {'type': 'relationship', 'rel_type': 'DEVELOPED', 'direction': 'outgoing'},\n",
    "    {'type': 'node', 'title': 'Theory of Relativity'}\n",
    "]\n",
    "\n",
    "triples = extract_path_triples(test_path)\n",
    "print(f\"Test path triples: {triples}\")\n",
    "\n",
    "# Test path scoring\n",
    "test_query = \"What did Einstein develop?\"\n",
    "if triples:\n",
    "    score = llm_score_path_relevance(test_query, triples)\n",
    "    print(f\"Relevance score for '{test_query}': {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141921d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What did Einstein develop?\n",
      "Triples: ['(Albert Einstein) -[DEVELOPED]-> (Theory of Relativity)', '(Theory of Relativity) -[PUBLISHED_IN]-> (1905)']\n",
      "Sufficient: True\n",
      "Generated answer: Einstein developed the Theory of Relativity.\n"
     ]
    }
   ],
   "source": [
    "def llm_check_sufficiency(query: str, combined_triples: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the combined triples are sufficient to answer the query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query\n",
    "        combined_triples (List[str]): Combined triples from all paths\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if sufficient, False otherwise\n",
    "    \"\"\"\n",
    "    if not combined_triples:\n",
    "        return False\n",
    "    \n",
    "    triples_text = \"\\n\".join(combined_triples)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Given the following knowledge graph triples, can you answer this query completely and accurately?\n",
    "    Answer only \"Yes\" or \"No\".\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Available triples:\n",
    "    {triples_text}\n",
    "    \n",
    "    Can this query be answered with the given information?\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ask_LLM(prompt)\n",
    "    if not response:\n",
    "        return False\n",
    "    \n",
    "    return response.strip().lower().startswith('yes')\n",
    "\n",
    "def llm_generate_answer(query: str, final_triples: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Generate the final answer using the selected triples.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query\n",
    "        final_triples (List[str]): Final set of triples to use for answering\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated answer\n",
    "    \"\"\"\n",
    "    if not final_triples:\n",
    "        return \"I don't have enough information to answer this query.\"\n",
    "    \n",
    "    triples_text = \"\\n\".join(final_triples)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the following knowledge graph triples, provide a comprehensive answer to the query.\n",
    "    Use only the information provided in the triples. Be factual and concise.\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Available knowledge:\n",
    "    {triples_text}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ask_LLM(prompt)\n",
    "    return response if response else \"Unable to generate an answer.\"\n",
    "\n",
    "def combine_triples_from_paths(paths: List[List[Dict]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Combine all triples from multiple paths, removing duplicates.\n",
    "    \n",
    "    Args:\n",
    "        paths (List[List[Dict]]): List of paths\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Combined unique triples\n",
    "    \"\"\"\n",
    "    all_triples = set()\n",
    "    \n",
    "    for path in paths:\n",
    "        triples = extract_path_triples(path)\n",
    "        all_triples.update(triples)\n",
    "    \n",
    "    return list(all_triples)\n",
    "\n",
    "# Test sufficiency checking\n",
    "test_triples = [\n",
    "    \"(Albert Einstein) -[DEVELOPED]-> (Theory of Relativity)\",\n",
    "    \"(Theory of Relativity) -[PUBLISHED_IN]-> (1905)\"\n",
    "]\n",
    "\n",
    "test_query = \"What did Einstein develop?\"\n",
    "is_sufficient = llm_check_sufficiency(test_query, test_triples)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Triples: {test_triples}\")\n",
    "print(f\"Sufficient: {is_sufficient}\")\n",
    "\n",
    "# Test answer generation\n",
    "if is_sufficient:\n",
    "    answer = llm_generate_answer(test_query, test_triples)\n",
    "    print(f\"Generated answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cda180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing the complete LLM-guided search algorithm:\n",
      "================================================================================\n",
      "üîç Starting LLM-guided search for: 'What is the relationship between Albert Einstein and physics?'\n",
      "üìù Step 1: Extracting entities...\n",
      "   Extracted entities: ['Albert Einstein', 'physics']\n",
      "üéØ Step 2: Finding initial nodes...\n",
      "   Found 3 initial nodes\n",
      "üõ§Ô∏è Step 3: Initializing paths...\n",
      "   Initialized 3 paths\n",
      "\n",
      "üîÑ Iteration 1/2\n",
      "   üåê Expanding paths...\n",
      "   Expanded from 3 to 16 paths\n",
      "   ‚úÇÔ∏è Pruning paths...\n",
      "   Kept 5 top paths\n",
      "   üß† Checking sufficiency...\n",
      "   Sufficient: True\n",
      "   ‚úÖ Sufficiency achieved! Stopping search.\n",
      "\n",
      "üìã Step 5: Generating final answer...\n",
      "‚úÖ Search completed!\n",
      "üìä Final statistics:\n",
      "   - Entities found: 2\n",
      "   - Initial nodes: 3\n",
      "   - Final paths: 5\n",
      "   - Final triples: 5\n",
      "\n",
      "üéØ FINAL ANSWER:\n",
      "Based on the available knowledge, there is a relationship between Albert Einstein and physics. However, Albert Einstein is not explicitly mentioned in the given knowledge.\n",
      "\n",
      "Given the context of the available knowledge, it can be inferred that the relationship between Albert Einstein and physics is likely through the Theory of Relativity. \n",
      "\n",
      "This is because the Theory of Relativity is related to (Rest (physics)) which might refer to a concept in physics attributed to Albert Einstein.\n",
      "\n",
      "A more precise answer cannot be provided due to the lack of direct information related to Albert Einstein in the given knowledge.\n"
     ]
    }
   ],
   "source": [
    "def llm_guided_search(query: str, top_k: int = 5, max_depth: int = 3, \n",
    "                     top_n_paths: int = 10, max_neighbors: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Main LLM-guided graph search algorithm.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input query\n",
    "        top_k (int): Number of initial nodes to retrieve\n",
    "        max_depth (int): Maximum search depth\n",
    "        top_n_paths (int): Number of paths to keep after pruning\n",
    "        max_neighbors (int): Maximum neighbors to explore per node\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated answer\n",
    "    \"\"\"\n",
    "    print(f\"üîç Starting LLM-guided search for: '{query}'\")\n",
    "    \n",
    "    # Step 1: Extract entities from query\n",
    "    print(\"üìù Step 1: Extracting entities...\")\n",
    "    entities = llm_extract_entities(query)\n",
    "    print(f\"   Extracted entities: {entities}\")\n",
    "    \n",
    "    if not entities:\n",
    "        return \"Could not extract any entities from the query.\"\n",
    "    \n",
    "    # Step 2: Retrieve initial nodes\n",
    "    print(\"üéØ Step 2: Finding initial nodes...\")\n",
    "    initial_nodes = find_similar_nodes(entities, top_k)\n",
    "    print(f\"   Found {len(initial_nodes)} initial nodes\")\n",
    "    \n",
    "    if not initial_nodes:\n",
    "        return \"Could not find any relevant nodes in the knowledge graph.\"\n",
    "    \n",
    "    # Step 3: Initialize paths\n",
    "    print(\"üõ§Ô∏è Step 3: Initializing paths...\")\n",
    "    paths = initialize_paths(initial_nodes)\n",
    "    print(f\"   Initialized {len(paths)} paths\")\n",
    "    \n",
    "    # Step 4: Iterative search loop\n",
    "    for depth in range(max_depth):\n",
    "        print(f\"\\nüîÑ Iteration {depth + 1}/{max_depth}\")\n",
    "        \n",
    "        # SEARCH: Expand paths by one hop\n",
    "        print(\"   üåê Expanding paths...\")\n",
    "        old_path_count = len(paths)\n",
    "        paths = expand_paths(paths, max_neighbors)\n",
    "        print(f\"   Expanded from {old_path_count} to {len(paths)} paths\")\n",
    "        \n",
    "        if not paths:\n",
    "            break\n",
    "        \n",
    "        # PRUNE: Keep only top N paths\n",
    "        print(\"   ‚úÇÔ∏è Pruning paths...\")\n",
    "        paths = prune_paths(query, paths, top_n_paths)\n",
    "        print(f\"   Kept {len(paths)} top paths\")\n",
    "        \n",
    "        # REASONING: Check sufficiency\n",
    "        print(\"   üß† Checking sufficiency...\")\n",
    "        combined_triples = combine_triples_from_paths(paths)\n",
    "        is_sufficient = llm_check_sufficiency(query, combined_triples)\n",
    "        print(f\"   Sufficient: {is_sufficient}\")\n",
    "        \n",
    "        if is_sufficient:\n",
    "            print(\"   ‚úÖ Sufficiency achieved! Stopping search.\")\n",
    "            break\n",
    "    \n",
    "    # Step 5: Generate final answer\n",
    "    print(\"\\nüìã Step 5: Generating final answer...\")\n",
    "    final_triples = combine_triples_from_paths(paths)\n",
    "    answer = llm_generate_answer(query, final_triples)\n",
    "    \n",
    "    print(f\"‚úÖ Search completed!\")\n",
    "    print(f\"üìä Final statistics:\")\n",
    "    print(f\"   - Entities found: {len(entities)}\")\n",
    "    print(f\"   - Initial nodes: {len(initial_nodes)}\")\n",
    "    print(f\"   - Final paths: {len(paths)}\")\n",
    "    print(f\"   - Final triples: {len(final_triples)}\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Test the complete algorithm with a simple query\n",
    "test_query = \"What is the relationship between Albert Einstein and physics?\"\n",
    "print(\"üöÄ Testing the complete LLM-guided search algorithm:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    result = llm_guided_search(test_query, top_k=3, max_depth=2, top_n_paths=5)\n",
    "    print(f\"\\nüéØ FINAL ANSWER:\")\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during search: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
